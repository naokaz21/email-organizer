"""
Email Organizer - Cloud Run Service
Gmailã‹ã‚‰è²©å£²å›³é¢ãƒ»ä½å®…åœ°å›³ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã—ã€Google Driveã«è‡ªå‹•æ•´ç†
"""

import os
import re
from flask import Flask, request, jsonify
from google.cloud import secretmanager
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from datetime import datetime, timedelta
from typing import Optional
import io
import unicodedata
import urllib.parse
from pypdf import PdfReader
import google.generativeai as genai
import googlemaps
from simulation import run_simulation, create_simulation_excel, format_simulation_summary_for_report

app = Flask(__name__)

# Secret Manager ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
secret_client = secretmanager.SecretManagerServiceClient()
PROJECT_ID = os.environ.get('GCP_PROJECT_ID')

def get_secret(secret_name):
    """Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
    name = f"projects/{PROJECT_ID}/secrets/{secret_name}/versions/latest"
    response = secret_client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

def get_gmail_service():
    """Gmail APIã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    client_id = get_secret("GMAIL_CLIENT_ID")
    client_secret = get_secret("GMAIL_CLIENT_SECRET")
    refresh_token = get_secret("GMAIL_REFRESH_TOKEN")

    # ä¿®æ­£ï¼šæ­£ã—ã„ã‚¹ã‚³ãƒ¼ãƒ—ã‚’æŒ‡å®š
    creds = Credentials(
        token=None,
        refresh_token=refresh_token,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=client_id,
        client_secret=client_secret,
        scopes=[
            "https://www.googleapis.com/auth/gmail.modify",
            "https://www.googleapis.com/auth/gmail.labels",
            "https://www.googleapis.com/auth/drive"  # drive.file â†’ drive ã«å¤‰æ›´
        ]
    )

    return build('gmail', 'v1', credentials=creds)

def get_drive_service():
    """Drive APIã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    client_id = get_secret("GMAIL_CLIENT_ID")
    client_secret = get_secret("GMAIL_CLIENT_SECRET")
    refresh_token = get_secret("GMAIL_REFRESH_TOKEN")

    # ä¿®æ­£ï¼šæ­£ã—ã„ã‚¹ã‚³ãƒ¼ãƒ—ã‚’æŒ‡å®š
    creds = Credentials(
        token=None,
        refresh_token=refresh_token,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=client_id,
        client_secret=client_secret,
        scopes=[
            "https://www.googleapis.com/auth/gmail.modify",
            "https://www.googleapis.com/auth/gmail.labels",
            "https://www.googleapis.com/auth/drive"  # drive.file â†’ drive ã«å¤‰æ›´
        ]
    )

    return build('drive', 'v3', credentials=creds)

def get_docs_service():
    """Docs APIã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    client_id = get_secret("GMAIL_CLIENT_ID")
    client_secret = get_secret("GMAIL_CLIENT_SECRET")
    refresh_token = get_secret("GMAIL_REFRESH_TOKEN")

    creds = Credentials(
        token=None,
        refresh_token=refresh_token,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=client_id,
        client_secret=client_secret,
        scopes=[
            "https://www.googleapis.com/auth/gmail.modify",
            "https://www.googleapis.com/auth/gmail.labels",
            "https://www.googleapis.com/auth/drive",
            "https://www.googleapis.com/auth/documents"
        ]
    )

    return build('docs', 'v1', credentials=creds)

def get_gmaps_client():
    """Google Maps APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    api_key = get_secret("GOOGLE_MAPS_API_KEY")
    return googlemaps.Client(key=api_key)

def get_gemini_client():
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    api_key = get_secret("GEMINI_API_KEY")
    genai.configure(api_key=api_key)
    # Gemini 2.5 Flash (2026å¹´ç¾åœ¨ã®æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã€1.5ã¯å»ƒæ­¢æ¸ˆã¿)
    return genai.GenerativeModel('gemini-2.5-flash')

def get_perplexity_client():
    """Perplexity APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆOpenAIäº’æ›ï¼‰"""
    try:
        # PERPLEXITY_API_KEYã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãªã‘ã‚Œã°ãƒ•ãƒªãƒ¼å±¤ã§å‹•ä½œï¼‰
        try:
            api_key = get_secret("PERPLEXITY_API_KEY")
            print("Perplexity API Keyå–å¾—æˆåŠŸï¼ˆæœ‰æ–™å±¤ï¼‰")
        except Exception:
            api_key = "pplx-dummy-key"  # ãƒ•ãƒªãƒ¼å±¤ç”¨
            print("Perplexity API Keyæœªè¨­å®šï¼ˆãƒ•ãƒªãƒ¼å±¤: 5ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/æ—¥ï¼‰")

        from openai import OpenAI
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.perplexity.ai"
        )
        return client

    except Exception as e:
        print(f"Perplexity ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_text_from_pdf(file_data: bytes) -> str:
    """PDFãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    try:
        pdf_file = io.BytesIO(file_data)
        reader = PdfReader(pdf_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        print(f"PDFè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def extract_text_from_image(file_data: bytes, gemini_client) -> str:
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆGemini Visionä½¿ç”¨ï¼‰"""
    try:
        import PIL.Image
        image = PIL.Image.open(io.BytesIO(file_data))

        prompt = """ã“ã®ç”»åƒã¯ä¸å‹•ç”£ã®è²©å£²å›³é¢ã§ã™ã€‚ç”»åƒå†…ã®ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š
- ä½æ‰€
- ç‰©ä»¶ç•ªå·
- å°‚æœ‰é¢ç©
- é–“å–ã‚Š
- ç¯‰å¹´æœˆ
- ç®¡ç†è²»
- ä¿®ç¹•ç©ç«‹é‡‘
- ãã®ä»–ã™ã¹ã¦ã®æ–‡å­—æƒ…å ±

ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ”¹è¡Œã§åŒºåˆ‡ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        response = gemini_client.generate_content([prompt, image])
        text = response.text.strip()
        print(f"ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†: {len(text)} æ–‡å­—")
        return text
    except Exception as e:
        print(f"ç”»åƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return ""

def parse_gemini_property_response(response_text: str) -> dict:
    """Geminiã®JSONå¿œç­”ã‚’å®‰å…¨ã«ãƒ‘ãƒ¼ã‚¹"""
    try:
        import json

        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json```ï¼‰ã‚’é™¤å»
        text = response_text.strip()
        if text.startswith('```'):
            # ```json ã§å§‹ã¾ã‚‹å ´åˆ
            text = text.split('```')[1]
            if text.startswith('json'):
                text = text[4:]
            text = text.strip()

        # JSON ãƒ‘ãƒ¼ã‚¹
        data = json.loads(text)

        # æ•°å€¤å‹ã¸ã®å¤‰æ›ï¼ˆæ–‡å­—åˆ—ã¨ã—ã¦è¿”ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
        # æ•°å€¤å¤‰æ›å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆbuilding_coverage_ratio, floor_area_ratioã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸æ–‡å­—åˆ—ã®ã¾ã¾ä¿æŒï¼‰
        numeric_fields = ['price', 'land_area', 'building_area', 'total_units',
                         'full_occupancy_rent', 'management_fee', 'reserve_fund']

        for field in numeric_fields:
            if field in data and data[field] is not None:
                try:
                    # ã‚«ãƒ³ãƒé™¤å»ã—ã¦æ•°å€¤å¤‰æ›
                    if isinstance(data[field], str):
                        data[field] = float(data[field].replace(',', ''))
                except (ValueError, AttributeError):
                    data[field] = None

        # rent_rollã®å„éƒ¨å±‹ã®æ•°å€¤ã‚‚å¤‰æ›
        if data.get('rent_roll') and isinstance(data['rent_roll'], list):
            for room in data['rent_roll']:
                if 'area' in room and room['area'] is not None:
                    try:
                        if isinstance(room['area'], str):
                            room['area'] = float(room['area'].replace(',', ''))
                    except (ValueError, AttributeError):
                        room['area'] = None
                if 'rent' in room and room['rent'] is not None:
                    try:
                        if isinstance(room['rent'], str):
                            room['rent'] = float(room['rent'].replace(',', ''))
                    except (ValueError, AttributeError):
                        room['rent'] = None

        return data

    except json.JSONDecodeError as e:
        print(f"JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text[:200]}...")
        return {}
    except Exception as e:
        print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def extract_comprehensive_property_data(file_data: bytes, filename: str, gemini_client) -> dict:
    """è²©å£²å›³é¢ã‹ã‚‰åŒ…æ‹¬çš„ãªç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºï¼ˆGeminiä½¿ç”¨ï¼‰"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¤å®š
        is_pdf = filename.lower().endswith('.pdf')
        is_image = filename.lower().endswith(('.jpg', '.jpeg', '.png'))

        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        if is_pdf:
            # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            text = extract_text_from_pdf(file_data)
            if not text:
                print("PDFã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—")
                return {}

            # Geminiã§æ§‹é€ åŒ–åˆ†æ
            prompt = f"""ã‚ãªãŸã¯ä¸å‹•ç”£è²©å£²å›³é¢ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€AIã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ†ã‚­ã‚¹ãƒˆã€‘
{text}

ã€æŠ½å‡ºé …ç›®ã€‘
1. åŸºæœ¬æƒ…å ±:
   - property_number: ç‰©ä»¶ç•ªå· (æ•°å­—ã®ã¿)
   - station: æœ€å¯„é§… (ã€Œé§…ã€ã‚’é™¤ãé§…åã®ã¿)
   - railway_line: æœ€å¯„é§…ã®è·¯ç·šå (ä¾‹: å°ç”°æ€¥æ±Ÿãƒå³¶ç·šã€JRæ±æµ·é“æœ¬ç·š)
   - address: ä½æ‰€ (å®Œå…¨ãªä½æ‰€)

2. ä¾¡æ ¼ãƒ»æ§‹é€ :
   - price: è²©å£²ä¾¡æ ¼ãƒ»ç‰©ä»¶ä¾¡æ ¼ (å††ã€æ•°å€¤ã®ã¿)
   - structure: æ§‹é€  (RC, SRC, æœ¨é€ ãªã©)
   - year_built: ç¯‰å¹´æœˆ (YYYYå¹´MMæœˆ ã¾ãŸã¯ YYYY/MMå½¢å¼)

3. é¢ç©ãƒ»è¦æ¨¡:
   - land_area: åœŸåœ°é¢ç© (ã¡ã€æ•°å€¤ã®ã¿)
   - building_area: å»ºç‰©é¢ç© (ã¡ã€æ•°å€¤ã®ã¿)
   - total_units: ç·æˆ¸æ•° (æ•°å€¤ã®ã¿)

4. è³ƒæ–™æƒ…å ±:
   - full_occupancy_rent: æº€å®¤æƒ³å®šè³ƒæ–™ (æœˆé¡å††ã€æ•°å€¤ã®ã¿)
   - floor_plan: é–“å–ã‚Š (ä¾‹: 1K, 1DK, 2LDK)
   - management_fee: ç®¡ç†è²» (æœˆé¡å††ã€æ•°å€¤ã®ã¿)
   - reserve_fund: ä¿®ç¹•ç©ç«‹é‡‘ (æœˆé¡å††ã€æ•°å€¤ã®ã¿)

5. æ¨©åˆ©ãƒ»æ³•è¦åˆ¶æƒ…å ±:
   - rights_type: æ¨©åˆ©å½¢æ…‹ (æ‰€æœ‰æ¨©ã€å€Ÿåœ°æ¨©ãªã©)
   - city_planning: éƒ½å¸‚è¨ˆç”» (å¸‚è¡—åŒ–åŒºåŸŸã€å¸‚è¡—åŒ–èª¿æ•´åŒºåŸŸãªã©)
   - zoning: ç”¨é€”åœ°åŸŸ (ç¬¬ä¸€ç¨®ä½å±…åœ°åŸŸã€å•†æ¥­åœ°åŸŸãªã©)
   - building_coverage_ratio: å»ºè”½ç‡ (ä¾‹: "60%")
   - floor_area_ratio: å®¹ç©ç‡ (ä¾‹: "200%")
   - road_access: æ¥é“çŠ¶æ³ (ä¾‹: "å—å´6må…¬é“")
   - transaction_type: å–å¼•æ…‹æ§˜ (åª’ä»‹ã€ä»²ä»‹ã€å£²ä¸»ãªã©)

6. ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« (éƒ¨å±‹åˆ¥è³ƒæ–™ä¸€è¦§):
   - rent_roll: é…åˆ—å½¢å¼ [{{"room": "éƒ¨å±‹ç•ªå·", "plan": "é–“å–ã‚Š", "area": é¢ç©, "rent": è³ƒæ–™}}, ...]

ã€ä¾¡æ ¼æŠ½å‡ºã«é–¢ã™ã‚‹é‡è¦æ³¨æ„ã€‘
- ã€Œè²©å£²ä¾¡æ ¼ã€ã€Œç‰©ä»¶ä¾¡æ ¼ã€ã€Œå£²å‡ºä¾¡æ ¼ã€ã¨æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹é‡‘é¡ã‚’priceã¨ã—ã¦æŠ½å‡ºã™ã‚‹ã“ã¨
- ã€ŒåœŸåœ°ä¾¡æ ¼ã€ã€ŒåœŸåœ°ä»£ã€ã¯ç‰©ä»¶å…¨ä½“ä¾¡æ ¼ã§ã¯ãªã„ãŸã‚ã€priceã«å…¥ã‚Œãªã„ã“ã¨
- åœŸåœ°ä¾¡æ ¼ã¨ç‰©ä»¶å…¨ä½“ä¾¡æ ¼ã‚’æ··åŒã—ãªã„ã‚ˆã†æ³¨æ„ã™ã‚‹ã“ã¨
- è¤‡æ•°ã®ä¾¡æ ¼ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ç‰©ä»¶å…¨ä½“ã®è²©å£²ä¾¡æ ¼ã‚’å„ªå…ˆã™ã‚‹ã“ã¨

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
- æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ null ã‚’è¨­å®š
- æ¨æ¸¬ã‚„è£œå®Œã¯ç¦æ­¢ã€è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã®ã¿æŠ½å‡º
- æ•°å€¤ã¯æ•°å­—ã®ã¿æŠ½å‡ºï¼ˆå˜ä½è¨˜å·ã€ã‚«ãƒ³ãƒã¯é™¤ãï¼‰
- å»ºè”½ç‡ãƒ»å®¹ç©ç‡ã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ä»˜ãã®æ–‡å­—åˆ—ã§ä¿æŒï¼ˆä¾‹: "60%"ï¼‰
- å‡ºåŠ›ã¯å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼

ã€å‡ºåŠ›å½¢å¼ã€‘
{{
  "property_number": "ç‰©ä»¶ç•ªå· or null",
  "station": "é§…å or null",
  "railway_line": "è·¯ç·šå or null",
  "address": "ä½æ‰€ or null",
  "price": ä¾¡æ ¼æ•°å€¤ or null,
  "structure": "æ§‹é€  or null",
  "year_built": "ç¯‰å¹´æœˆ or null",
  "land_area": é¢ç©æ•°å€¤ or null,
  "building_area": é¢ç©æ•°å€¤ or null,
  "total_units": æˆ¸æ•° or null,
  "full_occupancy_rent": è³ƒæ–™æ•°å€¤ or null,
  "floor_plan": "é–“å–ã‚Š or null",
  "management_fee": ç®¡ç†è²»æ•°å€¤ or null,
  "reserve_fund": ç©ç«‹é‡‘æ•°å€¤ or null,
  "rights_type": "æ¨©åˆ©å½¢æ…‹ or null",
  "city_planning": "éƒ½å¸‚è¨ˆç”» or null",
  "zoning": "ç”¨é€”åœ°åŸŸ or null",
  "building_coverage_ratio": "å»ºè”½ç‡ or null",
  "floor_area_ratio": "å®¹ç©ç‡ or null",
  "road_access": "æ¥é“çŠ¶æ³ or null",
  "transaction_type": "å–å¼•æ…‹æ§˜ or null",
  "rent_roll": [é…åˆ—] or null
}}
"""
            response = gemini_client.generate_content(prompt)
            result = parse_gemini_property_response(response.text)
            print(f"PDFè©³ç´°æŠ½å‡ºå®Œäº†: {len(result)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
            return result

        elif is_image:
            # Gemini Visionã§ç”»åƒã‚’ç›´æ¥åˆ†æ
            import PIL.Image
            image = PIL.Image.open(io.BytesIO(file_data))

            prompt = """ã‚ãªãŸã¯ä¸å‹•ç”£è²©å£²å›³é¢ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€AIã§ã™ã€‚

ã“ã®ç”»åƒã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
1. åŸºæœ¬æƒ…å ±:
   - property_number: ç‰©ä»¶ç•ªå· (æ•°å­—ã®ã¿)
   - station: æœ€å¯„é§… (ã€Œé§…ã€ã‚’é™¤ãé§…åã®ã¿)
   - railway_line: æœ€å¯„é§…ã®è·¯ç·šå (ä¾‹: å°ç”°æ€¥æ±Ÿãƒå³¶ç·šã€JRæ±æµ·é“æœ¬ç·š)
   - address: ä½æ‰€ (å®Œå…¨ãªä½æ‰€)

2. ä¾¡æ ¼ãƒ»æ§‹é€ :
   - price: è²©å£²ä¾¡æ ¼ãƒ»ç‰©ä»¶ä¾¡æ ¼ (å††ã€æ•°å€¤ã®ã¿)
   - structure: æ§‹é€  (RC, SRC, æœ¨é€ ãªã©)
   - year_built: ç¯‰å¹´æœˆ (YYYYå¹´MMæœˆ ã¾ãŸã¯ YYYY/MMå½¢å¼)

3. é¢ç©ãƒ»è¦æ¨¡:
   - land_area: åœŸåœ°é¢ç© (ã¡ã€æ•°å€¤ã®ã¿)
   - building_area: å»ºç‰©é¢ç© (ã¡ã€æ•°å€¤ã®ã¿)
   - total_units: ç·æˆ¸æ•° (æ•°å€¤ã®ã¿)

4. è³ƒæ–™æƒ…å ±:
   - full_occupancy_rent: æº€å®¤æƒ³å®šè³ƒæ–™ (æœˆé¡å††ã€æ•°å€¤ã®ã¿)
   - floor_plan: é–“å–ã‚Š (ä¾‹: 1K, 1DK, 2LDK)
   - management_fee: ç®¡ç†è²» (æœˆé¡å††ã€æ•°å€¤ã®ã¿)
   - reserve_fund: ä¿®ç¹•ç©ç«‹é‡‘ (æœˆé¡å††ã€æ•°å€¤ã®ã¿)

5. æ¨©åˆ©ãƒ»æ³•è¦åˆ¶æƒ…å ±:
   - rights_type: æ¨©åˆ©å½¢æ…‹ (æ‰€æœ‰æ¨©ã€å€Ÿåœ°æ¨©ãªã©)
   - city_planning: éƒ½å¸‚è¨ˆç”» (å¸‚è¡—åŒ–åŒºåŸŸã€å¸‚è¡—åŒ–èª¿æ•´åŒºåŸŸãªã©)
   - zoning: ç”¨é€”åœ°åŸŸ (ç¬¬ä¸€ç¨®ä½å±…åœ°åŸŸã€å•†æ¥­åœ°åŸŸãªã©)
   - building_coverage_ratio: å»ºè”½ç‡ (ä¾‹: "60%")
   - floor_area_ratio: å®¹ç©ç‡ (ä¾‹: "200%")
   - road_access: æ¥é“çŠ¶æ³ (ä¾‹: "å—å´6må…¬é“")
   - transaction_type: å–å¼•æ…‹æ§˜ (åª’ä»‹ã€ä»²ä»‹ã€å£²ä¸»ãªã©)

6. ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« (éƒ¨å±‹åˆ¥è³ƒæ–™ä¸€è¦§):
   - rent_roll: é…åˆ—å½¢å¼ [{"room": "éƒ¨å±‹ç•ªå·", "plan": "é–“å–ã‚Š", "area": é¢ç©, "rent": è³ƒæ–™}, ...]

ã€ä¾¡æ ¼æŠ½å‡ºã«é–¢ã™ã‚‹é‡è¦æ³¨æ„ã€‘
- ã€Œè²©å£²ä¾¡æ ¼ã€ã€Œç‰©ä»¶ä¾¡æ ¼ã€ã€Œå£²å‡ºä¾¡æ ¼ã€ã¨æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹é‡‘é¡ã‚’priceã¨ã—ã¦æŠ½å‡ºã™ã‚‹ã“ã¨
- ã€ŒåœŸåœ°ä¾¡æ ¼ã€ã€ŒåœŸåœ°ä»£ã€ã¯ç‰©ä»¶å…¨ä½“ä¾¡æ ¼ã§ã¯ãªã„ãŸã‚ã€priceã«å…¥ã‚Œãªã„ã“ã¨
- åœŸåœ°ä¾¡æ ¼ã¨ç‰©ä»¶å…¨ä½“ä¾¡æ ¼ã‚’æ··åŒã—ãªã„ã‚ˆã†æ³¨æ„ã™ã‚‹ã“ã¨
- è¤‡æ•°ã®ä¾¡æ ¼ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ç‰©ä»¶å…¨ä½“ã®è²©å£²ä¾¡æ ¼ã‚’å„ªå…ˆã™ã‚‹ã“ã¨

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
- æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ null ã‚’è¨­å®š
- æ¨æ¸¬ã‚„è£œå®Œã¯ç¦æ­¢ã€è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ã®ã¿æŠ½å‡º
- æ•°å€¤ã¯æ•°å­—ã®ã¿æŠ½å‡ºï¼ˆå˜ä½è¨˜å·ã€ã‚«ãƒ³ãƒã¯é™¤ãï¼‰
- å»ºè”½ç‡ãƒ»å®¹ç©ç‡ã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ä»˜ãã®æ–‡å­—åˆ—ã§ä¿æŒï¼ˆä¾‹: "60%"ï¼‰
- å‡ºåŠ›ã¯å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼

ã€å‡ºåŠ›å½¢å¼ã€‘
{
  "property_number": "ç‰©ä»¶ç•ªå· or null",
  "station": "é§…å or null",
  "railway_line": "è·¯ç·šå or null",
  "address": "ä½æ‰€ or null",
  "price": ä¾¡æ ¼æ•°å€¤ or null,
  "structure": "æ§‹é€  or null",
  "year_built": "ç¯‰å¹´æœˆ or null",
  "land_area": é¢ç©æ•°å€¤ or null,
  "building_area": é¢ç©æ•°å€¤ or null,
  "total_units": æˆ¸æ•° or null,
  "full_occupancy_rent": è³ƒæ–™æ•°å€¤ or null,
  "floor_plan": "é–“å–ã‚Š or null",
  "management_fee": ç®¡ç†è²»æ•°å€¤ or null,
  "reserve_fund": ç©ç«‹é‡‘æ•°å€¤ or null,
  "rights_type": "æ¨©åˆ©å½¢æ…‹ or null",
  "city_planning": "éƒ½å¸‚è¨ˆç”» or null",
  "zoning": "ç”¨é€”åœ°åŸŸ or null",
  "building_coverage_ratio": "å»ºè”½ç‡ or null",
  "floor_area_ratio": "å®¹ç©ç‡ or null",
  "road_access": "æ¥é“çŠ¶æ³ or null",
  "transaction_type": "å–å¼•æ…‹æ§˜ or null",
  "rent_roll": [é…åˆ—] or null
}
"""
            response = gemini_client.generate_content([prompt, image])
            result = parse_gemini_property_response(response.text)
            print(f"ç”»åƒè©³ç´°æŠ½å‡ºå®Œäº†: {len(result)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
            return result

        else:
            print(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {filename}")
            return {}

    except Exception as e:
        print(f"åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return {}

def is_hanbaizumen(text: str) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‹ã‚‰è²©å£²å›³é¢ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰"""
    # è²©å£²å›³é¢ã«ç‰¹æœ‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    keywords = [
        'è²©å£²å›³é¢',
        'ç‰©ä»¶ç•ªå·',
        'å°‚æœ‰é¢ç©',
        'é–“å–ã‚Š',
        'ãƒãƒ«ã‚³ãƒ‹ãƒ¼é¢ç©',
        'ç¯‰å¹´æœˆ',
        'ç·æˆ¸æ•°',
        'ç®¡ç†è²»',
        'ä¿®ç¹•ç©ç«‹é‡‘',
        'è²©å£²ä¾¡æ ¼',  # Phase 1ã§è¿½åŠ 
        'æ§‹é€ ',  # Phase 1ã§è¿½åŠ 
        'æº€å®¤æƒ³å®šè³ƒæ–™',  # Phase 1ã§è¿½åŠ 
        'ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«'  # Phase 1ã§è¿½åŠ 
    ]

    # 3ã¤ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è²©å£²å›³é¢ã¨åˆ¤å®š
    match_count = sum(1 for keyword in keywords if keyword in text)
    print(f"è²©å£²å›³é¢åˆ¤å®š: {match_count}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ")
    return match_count >= 3

def extract_address_with_regex(text: str) -> Optional[str]:
    """æ­£è¦è¡¨ç¾ã§ä½æ‰€ã‚’æŠ½å‡º"""
    patterns = [
        r'(æ±äº¬éƒ½|å¤§é˜ªåºœ|äº¬éƒ½åºœ|åŒ—æµ·é“|[ä¸€-é¾¥]+çœŒ)[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+å¸‚[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+',
        r'(æ±äº¬éƒ½|å¤§é˜ªåºœ|äº¬éƒ½åºœ|åŒ—æµ·é“|[ä¸€-é¾¥]+çœŒ)[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+åŒº[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+',
        r'æ±äº¬éƒ½[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+åŒº[ä¸€-é¾¥ã-ã‚“a-zA-Z0-9ãƒ¼\s]+[0-9]+',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(0)
    return None

def extract_address_with_gemini(text: str, gemini_client) -> Optional[str]:
    """Gemini APIã§ä½æ‰€ã‚’æŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    try:
        prompt = f"""
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸å‹•ç”£ç‰©ä»¶ã®ä½æ‰€ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ä½æ‰€ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ä¸è¦ï¼‰ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{text[:2000]}
"""
        response = gemini_client.generate_content(prompt)
        address = response.text.strip()
        return address if address else None
    except Exception as e:
        print(f"Geminiä½æ‰€æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def _clean_address(address: str) -> str:
    """ä½æ‰€æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå…¨è§’åŠè§’çµ±ä¸€ã€ä½™åˆ†ãªç©ºç™½é™¤å»ï¼‰"""
    # NFKCæ­£è¦åŒ–ï¼ˆå…¨è§’è‹±æ•°â†’åŠè§’ã€åŠè§’ã‚«ãƒŠâ†’å…¨è§’ãªã©ï¼‰
    cleaned = unicodedata.normalize('NFKC', address)
    # ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»
    cleaned = re.sub(r'\s+', '', cleaned)
    # å…ˆé ­ãƒ»æœ«å°¾ã®ç©ºç™½é™¤å»
    cleaned = cleaned.strip()
    return cleaned


def geocode_address(address: str, gmaps_client) -> Optional[dict]:
    """ä½æ‰€ã‹ã‚‰ä½ç½®æƒ…å ±ã‚’å–å¾—"""
    try:
        cleaned = _clean_address(address)
        print(f"Geocoding: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œä½æ‰€='{cleaned}'")
        geocode_result = gmaps_client.geocode(cleaned, language='ja', region='jp')
        if geocode_result:
            location = geocode_result[0]['geometry']['location']
            formatted_address = geocode_result[0]['formatted_address']
            return {
                'lat': location['lat'],
                'lng': location['lng'],
                'formatted_address': formatted_address,
                'original_address': cleaned
            }
        return None
    except Exception as e:
        print(f"Geocoding ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def calculate_walking_distance(location: dict, station: str, gmaps_client) -> Optional[dict]:
    """Google Maps Distance Matrix APIã§ç‰©ä»¶ã‹ã‚‰æœ€å¯„é§…ã¾ã§ã®å¾’æ­©è·é›¢ãƒ»æ™‚é–“ã‚’å–å¾—"""
    try:
        origin = f"{location['lat']},{location['lng']}"
        destination = f"{station}é§…"

        result = gmaps_client.distance_matrix(
            origins=[origin],
            destinations=[destination],
            mode='walking',
            language='ja',
            region='jp'
        )

        if result['status'] == 'OK':
            element = result['rows'][0]['elements'][0]
            if element['status'] == 'OK':
                distance_info = {
                    'distance_text': element['distance']['text'],
                    'distance_meters': element['distance']['value'],
                    'duration_text': element['duration']['text'],
                    'duration_seconds': element['duration']['value'],
                    'duration_minutes': round(element['duration']['value'] / 60),
                }
                print(f"å¾’æ­©è·é›¢è¨ˆç®—å®Œäº†: {station}é§…ã¾ã§ {distance_info['distance_text']} / {distance_info['duration_text']}")
                return distance_info
            else:
                print(f"Distance Matrixè¦ç´ ã‚¨ãƒ©ãƒ¼: {element['status']}")
                return None
        else:
            print(f"Distance Matrixã‚¨ãƒ©ãƒ¼: {result['status']}")
            return None
    except Exception as e:
        print(f"å¾’æ­©è·é›¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def research_market_price(location: dict, property_info: dict, gemini_client) -> dict:
    """Gemini APIã§å‘¨è¾ºç›¸å ´ã‚’èª¿æŸ»"""
    try:
        address = location.get('original_address') or location['formatted_address']
        station = property_info.get('station', 'ä¸æ˜')
        walking_info = property_info.get('walking_distance')
        walking_desc = ""
        walking_minutes = 'ä¸æ˜'
        if walking_info:
            walking_minutes = walking_info['duration_minutes']
            walking_desc = f"\n- æœ€å¯„é§…ã¾ã§ã®å¾’æ­©è·é›¢: {walking_info['distance_text']}ï¼ˆå¾’æ­©{walking_minutes}åˆ†ï¼‰â€»Google Maps Distance Matrix APIå®Ÿæ¸¬å€¤"

        # ç‰©ä»¶ã‚¹ãƒšãƒƒã‚¯æƒ…å ±ã‚’æ§‹ç¯‰
        spec_lines = []
        if property_info.get('structure'):
            spec_lines.append(f"- æ§‹é€ : {property_info['structure']}")
        if property_info.get('year_built'):
            spec_lines.append(f"- ç¯‰å¹´æœˆ: {property_info['year_built']}")
        if property_info.get('floor_plan'):
            spec_lines.append(f"- é–“å–ã‚Š: {property_info['floor_plan']}")
        if property_info.get('building_area'):
            spec_lines.append(f"- å»ºç‰©é¢ç©: {property_info['building_area']}ã¡")
        if property_info.get('total_units'):
            spec_lines.append(f"- ç·æˆ¸æ•°: {int(property_info['total_units'])}æˆ¸")
        spec_text = "\n".join(spec_lines)

        prompt = f"""
ã‚ãªãŸã¯ä¸å‹•ç”£æŠ•è³‡ã®å°‚é–€å®¶ã§ã™ã€‚

ã€é‡è¦ã€‘èª¿æŸ»å¯¾è±¡ã®ç‰©ä»¶ä½æ‰€: {address}
ã€é‡è¦ã€‘èª¿æŸ»å¯¾è±¡ã®æœ€å¯„é§…: {station}é§…
ã€é‡è¦ã€‘ä¸Šè¨˜ã®ä½æ‰€ãƒ»é§…ã®å‘¨è¾ºã®å®¶è³ƒç›¸å ´ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚
ã€é‡è¦ã€‘ä»–ã®éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘ã®ç‰©ä»¶æƒ…å ±ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚{station}é§…å‘¨è¾ºã®ç‰©ä»¶ã®ã¿å¯¾è±¡ã§ã™ã€‚

ç‰©ä»¶æƒ…å ±:
- ä½æ‰€: {address}
- ç·¯åº¦çµŒåº¦: {location['lat']}, {location['lng']}
- é§…: {station}{walking_desc}
- ç‰©ä»¶ç•ªå·: {property_info.get('property_number')}
{spec_text}

ã€é¡ä¼¼ç‰©ä»¶ã®æ¤œç´¢æ¡ä»¶ï¼ˆé‡è¦ï¼‰ã€‘
ä»¥ä¸‹ã®æ¡ä»¶ã‚’ã§ãã‚‹é™ã‚ŠæƒãˆãŸé¡ä¼¼ç‰©ä»¶ã‚’æŒ™ã’ã¦ãã ã•ã„:
1. ã‚¨ãƒªã‚¢: {station}é§…å‘¨è¾ºï¼ˆåŒä¸€é§…ã‚‚ã—ãã¯éš£æ¥é§…ã€åŒã˜éƒ½é“åºœçœŒå†…ï¼‰
2. é§…å¾’æ­©åˆ†æ•°: å¾’æ­©{walking_minutes}åˆ†å‰å¾Œï¼ˆÂ±5åˆ†ä»¥å†…ï¼‰
3. ç¯‰å¹´æ•°: {property_info.get('year_built', 'ä¸æ˜')}å‰å¾Œï¼ˆÂ±10å¹´ä»¥å†…ï¼‰
4. å°‚æœ‰é¢ç©: {property_info.get('building_area', 'ä¸æ˜')}ã¡å‰å¾Œ
5. é–“å–ã‚Š: {property_info.get('floor_plan', 'ä¸æ˜')}ã¨åŒç­‰
6. æ§‹é€ : {property_info.get('structure', 'ä¸æ˜')}ã¨åŒç­‰

ã€é§…è·é›¢ã«é–¢ã™ã‚‹æ³¨æ„ã€‘
é§…ã¾ã§ã®è·é›¢ãƒ»å¾’æ­©æ™‚é–“ã«ã¤ã„ã¦è¨€åŠã™ã‚‹å ´åˆã¯ã€ä¸Šè¨˜ã®Google Mapså®Ÿæ¸¬å€¤ï¼ˆå¾’æ­©{walking_minutes}åˆ†ï¼‰ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ç‹¬è‡ªã«æ¨æ¸¬ã—ãŸè·é›¢ã‚’è¨˜è¼‰ã—ãªã„ã§ãã ã•ã„ã€‚

ä»¥ä¸‹ã®å½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ï¼ˆæ§‹é€ åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ï¼‰:

[HEADING]å‘¨è¾ºã‚¨ãƒªã‚¢ã®ç‰¹å¾´[/HEADING]
{address}å‘¨è¾ºï¼ˆ{station}é§…ã‚¨ãƒªã‚¢ï¼‰ã®ç‰¹å¾´ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

[HEADING]é¡ä¼¼ç‰©ä»¶ã®å®¶è³ƒç›¸å ´[/HEADING]
{station}é§…å‘¨è¾ºã§ã€ä¸Šè¨˜ã®æ¤œç´¢æ¡ä»¶ã«è¿‘ã„é¡ä¼¼ç‰©ä»¶ã®å®¶è³ƒç›¸å ´ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚

[TABLE]
ç‰©ä»¶å | æ‰€åœ¨åœ° | é–“å–ã‚Š/é¢ç© | ç¯‰å¹´ | é§…å¾’æ­© | æœˆé¡è³ƒæ–™
â—‹â—‹ãƒãƒ³ã‚·ãƒ§ãƒ³ | {station}é§…å‘¨è¾º | 1K/25ã¡ | 2010å¹´ | å¾’æ­©â—‹åˆ† | â—‹ä¸‡å††
[/TABLE]

å…·ä½“çš„ãªç‰©ä»¶åï¼ˆãƒãƒ³ã‚·ãƒ§ãƒ³åãƒ»ã‚¢ãƒ‘ãƒ¼ãƒˆåï¼‰ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚
å¯èƒ½ãªé™ã‚Šå‚ç…§URLï¼ˆSUUMOã€HOME'Sã€at homeç­‰ã®ä¸å‹•ç”£ã‚µã‚¤ãƒˆï¼‰ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
ä¾‹: â—‹â—‹ãƒãƒ³ã‚·ãƒ§ãƒ³ï¼ˆ1K/25ã¡ï¼‰: æœˆé¡5.5ä¸‡å†† (å‚ç…§: https://suumo.jp/...)

[HEADING]ç›¸å ´ã®æ ¹æ‹ ã¨ãªã‚‹æƒ…å ±æº[/HEADING]
å‚ç…§å…ƒã®URLã‚„æƒ…å ±æºã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚

[HEADING]æŠ•è³‡è¦³ç‚¹ã§ã®è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ[/HEADING]
{address}å‘¨è¾ºã®è³ƒè²¸å¸‚å ´ã«ãŠã‘ã‚‹æŠ•è³‡è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ï¼ˆ#ã€##ã€###ã€**ã€*ã€```ç­‰ï¼‰ã¯ä¸€åˆ‡ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
ä¸Šè¨˜ã®[HEADING][/HEADING]ã‚¿ã‚°ã¨[TABLE][/TABLE]ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ã£ã¦ãã ã•ã„ã€‚

æœ€å¾Œã«æ”¹ã‚ã¦ç¢ºèª: ä¸Šè¨˜ã¯ã™ã¹ã¦{address}ï¼ˆ{station}é§…å‘¨è¾ºï¼‰ã®æƒ…å ±ã§ã™ã€‚ä»–ã®éƒ½é“åºœçœŒã®æƒ…å ±ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""
        response = gemini_client.generate_content(prompt)
        return {
            'status': 'success',
            'report': response.text,
            'model': 'gemini-2.0-flash-exp'
        }
    except Exception as e:
        print(f"Geminiç›¸å ´èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'report': 'ç›¸å ´èª¿æŸ»ã«å¤±æ•—ã—ã¾ã—ãŸã€‚'
        }

def research_area_with_gemini_search(location: dict, property_info: dict, gemini_client) -> dict:
    """Geminiã§ã‚¨ãƒªã‚¢èª¿æŸ»ï¼ˆWeb Search groundingãªã—ï¼çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å›ç­”ï¼‰"""
    try:
        address = location.get('original_address') or location['formatted_address']
        station = property_info.get('station', 'ä¸æ˜')
        walking_info = property_info.get('walking_distance')
        walking_desc = ""
        walking_table_row = ""
        if walking_info:
            walking_desc = f"\n- æœ€å¯„é§…ã¾ã§ã®å¾’æ­©è·é›¢: {walking_info['distance_text']}ï¼ˆå¾’æ­©{walking_info['duration_minutes']}åˆ†ï¼‰â€»Google Mapså®Ÿæ¸¬å€¤"
            walking_table_row = f"\nç‰©ä»¶ã‹ã‚‰ã®å¾’æ­©è·é›¢ | {walking_info['distance_text']}ï¼ˆå¾’æ­©{walking_info['duration_minutes']}åˆ†ï¼‰â€»Google Mapså®Ÿæ¸¬å€¤"
        prompt = f"""
ã€é‡è¦ã€‘èª¿æŸ»å¯¾è±¡ã‚¨ãƒªã‚¢: {address}
ã€é‡è¦ã€‘èª¿æŸ»å¯¾è±¡ã®æœ€å¯„é§…: {station}é§…
ã€é‡è¦ã€‘{address}å‘¨è¾ºã®æƒ…å ±ã®ã¿å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚ãªãŸã¯ä¸å‹•ç”£æŠ•è³‡ã‚¨ãƒªã‚¢åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ç‰©ä»¶ã‚¨ãƒªã‚¢ï¼ˆ{address}ã€{station}é§…å‘¨è¾ºï¼‰ã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚

ç‰©ä»¶æƒ…å ±:
- ä½æ‰€: {address}
- ç·¯åº¦çµŒåº¦: {location['lat']}, {location['lng']}
- é§…: {station}{walking_desc}

ã€é§…è·é›¢ã«é–¢ã™ã‚‹æ³¨æ„ã€‘
é§…ã¾ã§ã®è·é›¢ãƒ»å¾’æ­©æ™‚é–“ã«ã¤ã„ã¦è¨€åŠã™ã‚‹å ´åˆã¯ã€ä¸Šè¨˜ã®Google Mapså®Ÿæ¸¬å€¤ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ç‹¬è‡ªã«æ¨æ¸¬ã—ãŸè·é›¢ã‚’è¨˜è¼‰ã—ãªã„ã§ãã ã•ã„ã€‚

ä»¥ä¸‹ã®5ã¤ã®è¦³ç‚¹ã§èª¿æŸ»ã—ã€æ§‹é€ åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

[HEADING]æœ€å¯„é§…æƒ…å ±[/HEADING]
[TABLE]
é …ç›® | å†…å®¹
æœ€å¯„é§… | {station}é§…
è·¯ç·šå | ï¼ˆè©²å½“ã™ã‚‹è·¯ç·šåï¼‰{walking_table_row}
1æ—¥ã‚ãŸã‚Šä¹—é™å®¢æ•° | â—‹â—‹äººï¼ˆâ—‹å¹´åº¦ï¼‰
ä¹—é™å®¢æ•°æ¨ç§»ï¼ˆ5å¹´é–“ï¼‰ | â—‹â—‹äººâ†’â—‹â—‹äººï¼ˆâ—‹%å¢—æ¸›ï¼‰
[/TABLE]
å‘¨è¾ºé§…ã¨ã®æ¯”è¼ƒã‚„è£œè¶³ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Œã°è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

[HEADING]è·¯ç·šä¾¡[/HEADING]
[TABLE]
å¹´åº¦ | è·¯ç·šä¾¡ï¼ˆå††/ã¡ï¼‰
2024 | â—‹â—‹å††
2023 | â—‹â—‹å††
2022 | â—‹â—‹å††
2021 | â—‹â—‹å††
2020 | â—‹â—‹å††
[/TABLE]
{address}ä»˜è¿‘ã®è·¯ç·šä¾¡ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚³ãƒ¡ãƒ³ãƒˆã€‚

[HEADING]äººå£å‹•æ…‹[/HEADING]
[TABLE]
é …ç›® | å†…å®¹
äººå£ï¼ˆæœ€æ–°ï¼‰ | â—‹â—‹äºº
éå»10å¹´æ¨ç§» | â—‹â—‹äººâ†’â—‹â—‹äºº
å˜èº«ä¸–å¸¯æ¯”ç‡ | â—‹â—‹%
ä¸»è¦å¹´é½¢å±¤ | â—‹â—‹ä»£ãŒâ—‹â—‹%
[/TABLE]
è³ƒè²¸éœ€è¦ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã€‚

[HEADING]ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—[/HEADING]
[TABLE]
ãƒªã‚¹ã‚¯ç¨®åˆ¥ | è©•ä¾¡ | è©³ç´°
æ´ªæ°´ãƒªã‚¹ã‚¯ | ä½/ä¸­/é«˜ | æµ¸æ°´æƒ³å®šâ—‹m
åœ°éœ‡ãƒªã‚¹ã‚¯ | ä½/ä¸­/é«˜ | æ¶²çŠ¶åŒ–â—‹â—‹
åœŸç ‚ç½å®³ãƒªã‚¹ã‚¯ | ä½/ä¸­/é«˜ | â—‹â—‹
[/TABLE]
ãƒªã‚¹ã‚¯è©•ä¾¡ã®è£œè¶³ã‚³ãƒ¡ãƒ³ãƒˆã€‚

[HEADING]å†é–‹ç™ºè¨ˆç”»[/HEADING]
{address}ï¼ˆ{station}é§…å‘¨è¾ºï¼‰ã®å†é–‹ç™ºè¨ˆç”»ãƒ»å¤§è¦æ¨¡é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»æ–°é§…è¨ˆç”»ãƒ»å•†æ¥­æ–½è¨­æ•´å‚™ç­‰ã®æƒ…å ±ã€‚

é‡è¦: å¯èƒ½ãªé™ã‚Šå‡ºå…¸URLã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ï¼ˆ#ã€##ã€###ã€**ã€*ã€```ç­‰ï¼‰ã¯ä¸€åˆ‡ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
ä¸Šè¨˜ã®[HEADING][/HEADING]ã‚¿ã‚°ã¨[TABLE][/TABLE]ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ã£ã¦ãã ã•ã„ã€‚

æœ€å¾Œã«æ”¹ã‚ã¦ç¢ºèª: ä¸Šè¨˜ã¯ã™ã¹ã¦{address}ï¼ˆ{station}é§…å‘¨è¾ºï¼‰ã®æƒ…å ±ã§ã™ã€‚æ±äº¬éƒ½åƒä»£ç”°åŒºæ°¸ç”°ç”ºã‚„ä»–ã®ã‚¨ãƒªã‚¢ã®æƒ…å ±ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""

        # google_search_retrievalã‚’ä½¿ã‚ãšé€šå¸¸ã®Geminiå‘¼ã³å‡ºã—ï¼ˆæ°¸ç”°ç”ºå•é¡Œã®å›é¿ï¼‰
        response = gemini_client.generate_content(prompt)

        report_text = response.text

        return {
            'status': 'success',
            'report': report_text,
            'model': 'gemini-2.5-flash'
        }

    except Exception as e:
        print(f"Geminiã‚¨ãƒªã‚¢èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return {
            'status': 'error',
            'error': str(e),
            'report': 'ã‚¨ãƒªã‚¢èª¿æŸ»ã«å¤±æ•—ã—ã¾ã—ãŸã€‚'
        }

def _strip_markdown(text: str) -> str:
    """Markdownè¨˜æ³•ã‚’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    # è¦‹å‡ºã—è¨˜å·ã‚’é™¤å» (### heading â†’ heading)
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
    # å¤ªå­—/æ–œä½“ã‚’é™¤å» (**text** â†’ text, *text* â†’ text)
    text = re.sub(r'\*{1,3}(.+?)\*{1,3}', r'\1', text)
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    text = re.sub(r'```[\s\S]*?```', '', text)
    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’é™¤å»
    text = re.sub(r'`([^`]+)`', r'\1', text)
    # ãƒªãƒ³ã‚¯ [text](url) â†’ text (url)
    text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1 (\2)', text)
    # æ°´å¹³ç·š --- ã‚’é™¤å»
    text = re.sub(r'^-{3,}$', '', text, flags=re.MULTILINE)
    # é€£ç¶šç©ºè¡Œã‚’1è¡Œã«
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


def combine_research_reports(gemini_market_report: dict, area_report: dict) -> str:
    """Geminiå¸‚å ´èª¿æŸ»ã¨ã‚¨ãƒªã‚¢èª¿æŸ»ã‚’çµ±åˆ"""
    combined_parts = []

    # Geminiå¸‚å ´èª¿æŸ»
    if gemini_market_report.get('status') == 'success':
        combined_parts.append("[HEADING]å¸‚å ´èª¿æŸ»[/HEADING]")
        combined_parts.append(gemini_market_report.get('report', ''))
    else:
        combined_parts.append("[HEADING]å¸‚å ´èª¿æŸ»[/HEADING]")
        combined_parts.append("å¸‚å ´èª¿æŸ»ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    combined_parts.append("")

    # ã‚¨ãƒªã‚¢èª¿æŸ»
    if area_report.get('status') == 'success':
        combined_parts.append("[HEADING]ã‚¨ãƒªã‚¢åˆ†æ[/HEADING]")
        combined_parts.append(area_report.get('report', ''))
    else:
        combined_parts.append("[HEADING]ã‚¨ãƒªã‚¢åˆ†æ[/HEADING]")
        combined_parts.append("ã‚¨ãƒªã‚¢åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

    return _strip_markdown("\n".join(combined_parts))


def _parse_structured_research_text(text: str) -> list:
    """æ§‹é€ åŒ–ã‚¿ã‚°ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã¦[(content, type)]ã®ãƒªã‚¹ãƒˆã«å¤‰æ›

    type: 'heading', 'table', 'text'
    """
    segments = []
    remaining = text

    while remaining:
        # [HEADING]...[/HEADING] ã‚’æ¤œç´¢
        heading_match = re.search(r'\[HEADING\](.*?)\[/HEADING\]', remaining)
        # [TABLE]...[/TABLE] ã‚’æ¤œç´¢
        table_match = re.search(r'\[TABLE\](.*?)\[/TABLE\]', remaining, re.DOTALL)

        # æ¬¡ã«è¦‹ã¤ã‹ã‚‹ã‚¿ã‚°ã‚’åˆ¤å®š
        next_match = None
        next_type = None

        if heading_match and table_match:
            if heading_match.start() < table_match.start():
                next_match = heading_match
                next_type = 'heading'
            else:
                next_match = table_match
                next_type = 'table'
        elif heading_match:
            next_match = heading_match
            next_type = 'heading'
        elif table_match:
            next_match = table_match
            next_type = 'table'

        if next_match is None:
            # ã‚¿ã‚°ãŒã‚‚ã†ãªã„ â†’ æ®‹ã‚Šã¯ã™ã¹ã¦ãƒ†ã‚­ã‚¹ãƒˆ
            stripped = remaining.strip()
            if stripped:
                segments.append((stripped, 'text'))
            break

        # ã‚¿ã‚°ã®å‰ã®ãƒ†ã‚­ã‚¹ãƒˆ
        before = remaining[:next_match.start()].strip()
        if before:
            segments.append((before, 'text'))

        # ã‚¿ã‚°è‡ªä½“
        segments.append((next_match.group(1).strip(), next_type))

        # æ®‹ã‚Šã‚’æ›´æ–°
        remaining = remaining[next_match.end():]

    return segments

def _find_placeholder_range(docs_service, doc_id, placeholder):
    """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è¡Œå…¨ä½“ã®start/endã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™"""
    doc = docs_service.documents().get(documentId=doc_id).execute()
    for element in doc['body']['content']:
        if 'paragraph' in element:
            full_text = ''
            for run in element['paragraph'].get('elements', []):
                full_text += run.get('textRun', {}).get('content', '')
            if placeholder in full_text:
                return element['startIndex'], element['endIndex']
    return None, None


# ãƒ‡ã‚¶ã‚¤ãƒ³å®šæ•°ï¼ˆMcKinsey/BCGå“è³ªï¼‰
_NAVY = {'red': 0.11, 'green': 0.18, 'blue': 0.33}      # #1C2E54 ãƒ€ãƒ¼ã‚¯ãƒã‚¤ãƒ“ãƒ¼
_LIGHT_NAVY = {'red': 0.22, 'green': 0.33, 'blue': 0.53}  # #385487
_HEADER_BG = {'red': 0.11, 'green': 0.18, 'blue': 0.33}   # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼èƒŒæ™¯
_HEADER_TEXT = {'red': 1.0, 'green': 1.0, 'blue': 1.0}     # ç™½æ–‡å­—
_ALT_ROW_BG = {'red': 0.95, 'green': 0.96, 'blue': 0.98}   # #F2F5FA äº¤äº’è¡Œ
_BORDER_COLOR = {'red': 0.80, 'green': 0.82, 'blue': 0.86}  # #CCD1DB è–„ã„ã‚°ãƒ¬ãƒ¼
_ACCENT = {'red': 0.16, 'green': 0.50, 'blue': 0.73}       # #2980BA ã‚¢ã‚¯ã‚»ãƒ³ãƒˆé’


def _rgb(color_dict):
    return {'color': {'rgbColor': color_dict}}


def _insert_table_at_placeholder(docs_service, doc_id, placeholder, rows_data, col_count):
    """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚¿ã‚¤ãƒ«ä»˜ããƒ†ãƒ¼ãƒ–ãƒ«ã«ç½®æ›"""
    start, end = _find_placeholder_range(docs_service, doc_id, placeholder)
    if start is None:
        print(f"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼æœªæ¤œå‡º: {placeholder}")
        return

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è¡Œã‚’å‰Šé™¤
    docs_service.documents().batchUpdate(
        documentId=doc_id,
        body={'requests': [{'deleteContentRange': {'range': {'startIndex': start, 'endIndex': end}}}]}
    ).execute()

    # ãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥
    row_count = len(rows_data)
    docs_service.documents().batchUpdate(
        documentId=doc_id,
        body={'requests': [{'insertTable': {
            'rows': row_count, 'columns': col_count,
            'location': {'index': start}
        }}]}
    ).execute()

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†å–å¾—ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’å–å¾—
    doc = docs_service.documents().get(documentId=doc_id).execute()
    table_element = None
    table_start_index = None
    for element in doc['body']['content']:
        if 'table' in element and element['startIndex'] >= start:
            table_element = element
            table_start_index = element['startIndex']
            break

    if not table_element:
        print(f"ãƒ†ãƒ¼ãƒ–ãƒ«æœªæ¤œå‡º: {placeholder}")
        return

    table = table_element['table']

    # ã‚»ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼ˆé€†é †ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãšã‚Œé˜²æ­¢ï¼‰
    cell_requests = []
    for r in range(row_count - 1, -1, -1):
        row = table['tableRows'][r]
        for c in range(col_count - 1, -1, -1):
            cell = row['tableCells'][c]
            cell_index = cell['content'][0]['paragraph']['elements'][0]['startIndex']
            text = str(rows_data[r][c]) if c < len(rows_data[r]) else ''
            if text:
                cell_requests.append({'insertText': {'location': {'index': cell_index}, 'text': text}})

    if cell_requests:
        docs_service.documents().batchUpdate(
            documentId=doc_id, body={'requests': cell_requests}
        ).execute()

    # === ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° ===
    style_requests = []

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: ãƒã‚¤ãƒ“ãƒ¼èƒŒæ™¯ + ç™½å¤ªå­—
    style_requests.append({
        'updateTableCellStyle': {
            'tableCellStyle': {
                'backgroundColor': _rgb(_HEADER_BG),
                'paddingTop': {'magnitude': 5, 'unit': 'PT'},
                'paddingBottom': {'magnitude': 5, 'unit': 'PT'},
                'paddingLeft': {'magnitude': 7, 'unit': 'PT'},
                'paddingRight': {'magnitude': 7, 'unit': 'PT'},
            },
            'fields': 'backgroundColor,paddingTop,paddingBottom,paddingLeft,paddingRight',
            'tableRange': {
                'tableCellLocation': {'tableStartLocation': {'index': table_start_index}, 'rowIndex': 0, 'columnIndex': 0},
                'rowSpan': 1, 'columnSpan': col_count
            }
        }
    })

    # ãƒ‡ãƒ¼ã‚¿è¡Œ: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° + äº¤äº’èƒŒæ™¯è‰²
    for r in range(1, row_count):
        bg = _ALT_ROW_BG if r % 2 == 0 else {'red': 1.0, 'green': 1.0, 'blue': 1.0}
        style_requests.append({
            'updateTableCellStyle': {
                'tableCellStyle': {
                    'backgroundColor': _rgb(bg),
                    'paddingTop': {'magnitude': 4, 'unit': 'PT'},
                    'paddingBottom': {'magnitude': 4, 'unit': 'PT'},
                    'paddingLeft': {'magnitude': 7, 'unit': 'PT'},
                    'paddingRight': {'magnitude': 7, 'unit': 'PT'},
                },
                'fields': 'backgroundColor,paddingTop,paddingBottom,paddingLeft,paddingRight',
                'tableRange': {
                    'tableCellLocation': {'tableStartLocation': {'index': table_start_index}, 'rowIndex': r, 'columnIndex': 0},
                    'rowSpan': 1, 'columnSpan': col_count
                }
            }
        })

    # å…¨ã‚»ãƒ«ã®ãƒœãƒ¼ãƒ€ãƒ¼: è–„ã„ã‚°ãƒ¬ãƒ¼
    style_requests.append({
        'updateTableCellStyle': {
            'tableCellStyle': {
                'borderTop': {'color': _rgb(_BORDER_COLOR), 'width': {'magnitude': 0.5, 'unit': 'PT'}, 'dashStyle': 'SOLID'},
                'borderBottom': {'color': _rgb(_BORDER_COLOR), 'width': {'magnitude': 0.5, 'unit': 'PT'}, 'dashStyle': 'SOLID'},
                'borderLeft': {'color': _rgb(_BORDER_COLOR), 'width': {'magnitude': 0.5, 'unit': 'PT'}, 'dashStyle': 'SOLID'},
                'borderRight': {'color': _rgb(_BORDER_COLOR), 'width': {'magnitude': 0.5, 'unit': 'PT'}, 'dashStyle': 'SOLID'},
            },
            'fields': 'borderTop,borderBottom,borderLeft,borderRight',
            'tableRange': {
                'tableCellLocation': {'tableStartLocation': {'index': table_start_index}, 'rowIndex': 0, 'columnIndex': 0},
                'rowSpan': row_count, 'columnSpan': col_count
            }
        }
    })

    if style_requests:
        try:
            docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': style_requests}).execute()
        except Exception as e:
            print(f"ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†å–å¾—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¤‰ã‚ã£ãŸãŸã‚ï¼‰
    doc = docs_service.documents().get(documentId=doc_id).execute()
    table_element = None
    for element in doc['body']['content']:
        if 'table' in element and element['startIndex'] >= start:
            table_element = element
            break

    if not table_element:
        return

    table = table_element['table']

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãƒ†ã‚­ã‚¹ãƒˆ: ç™½ãƒ»å¤ªå­—ãƒ»ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    text_requests = []
    header_row = table['tableRows'][0]
    for c in range(col_count):
        cell = header_row['tableCells'][c]
        el = cell['content'][0]['paragraph']['elements'][0]
        cs = el['startIndex']
        ce = el.get('endIndex', cs)
        if ce > cs:
            text_requests.append({
                'updateTextStyle': {
                    'range': {'startIndex': cs, 'endIndex': ce - 1},
                    'textStyle': {
                        'bold': True,
                        'foregroundColor': _rgb(_HEADER_TEXT),
                        'fontSize': {'magnitude': 9, 'unit': 'PT'},
                    },
                    'fields': 'bold,foregroundColor,fontSize'
                }
            })

    # ãƒ‡ãƒ¼ã‚¿è¡Œãƒ†ã‚­ã‚¹ãƒˆ: ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºçµ±ä¸€
    for r in range(1, row_count):
        row = table['tableRows'][r]
        for c in range(col_count):
            cell = row['tableCells'][c]
            el = cell['content'][0]['paragraph']['elements'][0]
            cs = el['startIndex']
            ce = el.get('endIndex', cs)
            if ce > cs:
                text_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': cs, 'endIndex': ce - 1},
                        'textStyle': {
                            'fontSize': {'magnitude': 9, 'unit': 'PT'},
                        },
                        'fields': 'fontSize'
                    }
                })

    if text_requests:
        try:
            docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': text_requests}).execute()
        except Exception:
            pass


def _search_nearby_places(lat: float, lng: float, api_key: str) -> dict:
    """Places API (New) ã§å‘¨è¾ºæ–½è¨­ã‚’æ¤œç´¢"""
    import requests as req

    facility_types = {
        'convenience_store': {'color': 'green', 'label': 'C'},
        'supermarket': {'color': 'blue', 'label': 'S'},
        'restaurant': {'color': 'orange', 'label': 'R'},
    }
    results = {}

    for place_type, marker_info in facility_types.items():
        try:
            resp = req.post(
                'https://places.googleapis.com/v1/places:searchNearby',
                headers={
                    'X-Goog-Api-Key': api_key,
                    'X-Goog-FieldMask': 'places.displayName,places.location,places.formattedAddress',
                    'Content-Type': 'application/json',
                },
                json={
                    'includedTypes': [place_type],
                    'maxResultCount': 3,
                    'locationRestriction': {
                        'circle': {
                            'center': {'latitude': lat, 'longitude': lng},
                            'radius': 500.0,
                        }
                    },
                },
                timeout=10,
            )
            if resp.status_code == 200:
                places = resp.json().get('places', [])
                results[place_type] = {
                    'places': places,
                    'color': marker_info['color'],
                    'label': marker_info['label'],
                }
                print(f"Places API: {place_type} â†’ {len(places)}ä»¶")
            else:
                print(f"Places API ã‚¨ãƒ©ãƒ¼ ({place_type}): HTTP {resp.status_code} - {resp.text[:200]}")
                results[place_type] = {'places': [], 'color': marker_info['color'], 'label': marker_info['label']}
        except Exception as e:
            print(f"Places API ä¾‹å¤– ({place_type}): {e}")
            results[place_type] = {'places': [], 'color': marker_info['color'], 'label': marker_info['label']}

    return results


def _insert_map_image(docs_service, drive_service, doc_id, location):
    """åœ°å›³ç”»åƒã‚’DriveçµŒç”±ã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½ç½®ã«æŒ¿å…¥ï¼ˆå‘¨è¾ºæ–½è¨­ãƒãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰"""
    try:
        import requests as req
        from googleapiclient.http import MediaIoBaseUpload

        start, end = _find_placeholder_range(docs_service, doc_id, '{{MAP_IMAGE}}')
        if start is None:
            print("åœ°å›³ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼æœªæ¤œå‡º")
            return

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å‰Šé™¤
        docs_service.documents().batchUpdate(
            documentId=doc_id,
            body={'requests': [{'deleteContentRange': {'range': {'startIndex': start, 'endIndex': end}}}]}
        ).execute()

        lat, lng = location['lat'], location['lng']
        api_key = get_secret("GOOGLE_MAPS_API_KEY")

        # å‘¨è¾ºæ–½è¨­ã‚’æ¤œç´¢
        nearby = _search_nearby_places(lat, lng, api_key)

        # ç‰©ä»¶ãƒãƒ¼ã‚«ãƒ¼ï¼ˆèµ¤ã€ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰
        markers_param = f"&markers=color:red%7Clabel:P%7C{lat},{lng}"

        # å‘¨è¾ºæ–½è¨­ãƒãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ 
        for place_type, info in nearby.items():
            for place in info.get('places', []):
                loc = place.get('location', {})
                p_lat = loc.get('latitude')
                p_lng = loc.get('longitude')
                if p_lat and p_lng:
                    markers_param += f"&markers=color:{info['color']}%7Clabel:{info['label']}%7C{p_lat},{p_lng}"

        # Google Maps Static API ã§ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆzoom=15ã€æ–½è¨­ãƒãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰
        map_url = (
            f"https://maps.googleapis.com/maps/api/staticmap"
            f"?center={lat},{lng}&zoom=15&size=600x400&scale=2&maptype=roadmap"
            f"{markers_param}"
            f"&key={api_key}"
        )
        resp = req.get(map_url, timeout=15)
        if resp.status_code != 200:
            print(f"åœ°å›³ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: HTTP {resp.status_code}")
            return

        # Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        image_data = io.BytesIO(resp.content)
        media = MediaIoBaseUpload(image_data, mimetype='image/png', resumable=False)
        map_file = drive_service.files().create(
            body={'name': 'map_temp.png', 'mimeType': 'image/png'},
            media_body=media, fields='id'
        ).execute()
        map_file_id = map_file['id']

        # å…¬é–‹URLã‚’è¨­å®šï¼ˆanyone can viewï¼‰
        drive_service.permissions().create(
            fileId=map_file_id,
            body={'type': 'anyone', 'role': 'reader'}
        ).execute()
        image_url = f"https://drive.google.com/uc?id={map_file_id}"

        # Google Mapsãƒªãƒ³ã‚¯ï¼ˆä½æ‰€ãƒ†ã‚­ã‚¹ãƒˆã§æ¤œç´¢ï¼‰
        addr_for_maps = location.get('original_address') or location.get('formatted_address', '')
        maps_link = f"https://www.google.com/maps/search/?api=1&query={urllib.parse.quote(addr_for_maps)}"

        # ç”»åƒæŒ¿å…¥
        docs_service.documents().batchUpdate(
            documentId=doc_id,
            body={'requests': [{
                'insertInlineImage': {
                    'uri': image_url,
                    'location': {'index': start},
                    'objectSize': {
                        'width': {'magnitude': 450, 'unit': 'PT'},
                        'height': {'magnitude': 300, 'unit': 'PT'},
                    }
                }
            }]}
        ).execute()

        # ç”»åƒã®å¾Œã«å‡¡ä¾‹ + ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
        legend_text = "\nğŸ”´ ç‰©ä»¶æ‰€åœ¨åœ°  ğŸŸ¢ ã‚³ãƒ³ãƒ“ãƒ‹  ğŸ”µ ã‚¹ãƒ¼ãƒ‘ãƒ¼  ğŸŸ  é£²é£Ÿåº—\n"
        link_label = "Google Mapsã§é–‹ã"
        after_text = f"{legend_text}{link_label}\n"
        link_index = start + 1

        docs_service.documents().batchUpdate(
            documentId=doc_id,
            body={'requests': [
                {'insertText': {'location': {'index': link_index}, 'text': after_text}},
                # å‡¡ä¾‹ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«
                {'updateTextStyle': {
                    'range': {'startIndex': link_index, 'endIndex': link_index + len(legend_text)},
                    'textStyle': {
                        'fontSize': {'magnitude': 8, 'unit': 'PT'},
                        'foregroundColor': _rgb({'red': 0.4, 'green': 0.4, 'blue': 0.4}),
                    },
                    'fields': 'fontSize,foregroundColor'
                }},
                # ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«
                {'updateTextStyle': {
                    'range': {
                        'startIndex': link_index + len(legend_text),
                        'endIndex': link_index + len(legend_text) + len(link_label),
                    },
                    'textStyle': {
                        'link': {'url': maps_link},
                        'foregroundColor': _rgb(_ACCENT),
                        'fontSize': {'magnitude': 9, 'unit': 'PT'},
                    },
                    'fields': 'link,foregroundColor,fontSize'
                }}
            ]}
        ).execute()

        print(f"åœ°å›³ç”»åƒæŒ¿å…¥å®Œäº†ï¼ˆå‘¨è¾ºæ–½è¨­ãƒãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰")

    except Exception as e:
        print(f"åœ°å›³ç”»åƒæŒ¿å…¥ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
        import traceback
        traceback.print_exc()


def create_evaluation_report(docs_service, drive_service, folder_id: str, report_data: dict, gemini_client=None) -> str:
    """Google Docsã§è¦ä»¶å®šç¾©æ›¸ã‚µãƒ³ãƒ—ãƒ«æº–æ‹ ã®æ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
    try:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
        title = f"ç‰©ä»¶è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ_{report_data['property_number']}_{report_data['station']}"
        doc = docs_service.documents().create(body={'title': title}).execute()
        doc_id = doc['documentId']

        detailed = report_data.get('detailed_data', {})
        sim_result = detailed.get('simulation_result')
        now = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')

        # === Step 1: ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’æ§‹ç¯‰ ===
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆã§ç®¡ç† (text, style) ã®ãƒšã‚¢
        # style: 'TITLE', 'HEADING_1', 'HEADING_2', 'NORMAL_TEXT'
        sections = []

        # ã‚¿ã‚¤ãƒˆãƒ«
        sections.append((f"{report_data['station']}_{report_data['property_number']} ç‰©ä»¶èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ", 'TITLE'))
        sections.append((f"èª¿æŸ»æ—¥ï¼š{now}", 'SUBTITLE'))

        # A1. ç‰©ä»¶æ¦‚è¦
        sections.append(("A1. ç‰©ä»¶æ¦‚è¦", 'HEADING_1'))
        sections.append(("åŸºæœ¬æƒ…å ±", 'HEADING_2'))
        sections.append(("{{TABLE_BASIC_INFO}}", 'NORMAL_TEXT'))

        # åœ°å›³
        location = report_data.get('location')
        if location and location.get('lat') and location.get('lng'):
            sections.append(("æ‰€åœ¨åœ°ãƒãƒƒãƒ—", 'HEADING_2'))
            sections.append(("{{MAP_IMAGE}}", 'NORMAL_TEXT'))

        # ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
        if detailed.get('rent_roll') and len(detailed['rent_roll']) > 0:
            sections.append(("ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«", 'HEADING_2'))
            sections.append(("{{TABLE_RENT_ROLL}}", 'NORMAL_TEXT'))

        # A2. å‘¨è¾ºç’°å¢ƒèª¿æŸ»ï¼ˆæ§‹é€ åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼‰
        sections.append(("A2. å‘¨è¾ºç’°å¢ƒèª¿æŸ»", 'HEADING_1'))
        market_text = report_data.get('market_report', 'èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ãªã—')
        research_segments = _parse_structured_research_text(market_text)
        for seg_content, seg_type in research_segments:
            if seg_type == 'heading':
                sections.append((seg_content, 'HEADING_2'))
            elif seg_type == 'table':
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã—ã¦è¿½åŠ ã—å¾Œã§å‡¦ç†
                table_id = f"RESEARCH_TABLE_{len(sections)}"
                sections.append((f"{{{{{table_id}}}}}", 'NORMAL_TEXT'))
                # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆå¾Œã§æŒ¿å…¥ï¼‰
                if not hasattr(create_evaluation_report, '_research_tables'):
                    create_evaluation_report._research_tables = {}
                create_evaluation_report._research_tables[table_id] = seg_content
            else:
                sections.append((seg_content, 'NORMAL_TEXT'))

        # A3. åç›Šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦
        sections.append(("A3. åç›Šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦", 'HEADING_1'))
        if sim_result:
            sections.append(("ä¸»è¦è¨­å®šæ¡ä»¶", 'HEADING_2'))
            sections.append(("{{TABLE_SIM_CONDITIONS}}", 'NORMAL_TEXT'))
            sections.append(("æŠ•è³‡åˆ†æçµæœ", 'HEADING_2'))
            sections.append(("{{TABLE_SIM_RESULTS}}", 'NORMAL_TEXT'))

            # åç›ŠæŒ‡æ¨™ã®å‡¡ä¾‹
            sections.append(("æŒ‡æ¨™ã®è§£èª¬", 'HEADING_2'))
            legend_text = (
                "è¡¨é¢åˆ©å›ã‚Š: æº€å®¤æƒ³å®šå¹´é–“è³ƒæ–™ / ç‰©ä»¶ä¾¡æ ¼ã€‚è³¼å…¥è«¸è²»ç”¨ã‚’å«ã¾ãªã„ç°¡æ˜“çš„ãªåç›Šæ€§æŒ‡æ¨™ã€‚ä¸€èˆ¬çš„ã«5%ä»¥ä¸ŠãŒç›®å®‰ã€‚\n\n"
                "FCRï¼ˆç·åç›Šç‡ï¼‰: åˆå¹´åº¦NOIï¼ˆå–¶æ¥­ç´”åˆ©ç›Šï¼‰ / ç·æŠ•è³‡é¡ï¼ˆç‰©ä»¶ä¾¡æ ¼ï¼‹è³¼å…¥è«¸è²»ç”¨ï¼‰ã€‚å®Ÿè³ªçš„ãªæŠ•è³‡åˆ©å›ã‚Šã‚’ç¤ºã™ã€‚\n\n"
                "K%ï¼ˆãƒ­ãƒ¼ãƒ³å®šæ•°ï¼‰: å¹´é–“è¿”æ¸ˆé¡ï¼ˆADSï¼‰ / å€Ÿå…¥é¡ã€‚å€Ÿå…¥ã‚³ã‚¹ãƒˆã®å‰²åˆã‚’ç¤ºã™ã€‚FCR > K% ã§ã‚ã‚Œã°ãƒ¬ãƒãƒ¬ãƒƒã‚¸ãŒæœ‰åŠ¹ã«æ©Ÿèƒ½ã—ã¦ã„ã‚‹ã€‚\n\n"
                "CCRï¼ˆè‡ªå·±è³‡æœ¬é…å½“ç‡ï¼‰: åˆå¹´åº¦ç¨å¼•å‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ / è‡ªå·±è³‡é‡‘ã€‚è‡ªå·±è³‡é‡‘ã«å¯¾ã™ã‚‹å®Ÿè³ªçš„ãªãƒªã‚¿ãƒ¼ãƒ³ã€‚FCR < CCR < K% ã®é–¢ä¿‚ãŒæœ›ã¾ã—ã„ã€‚\n\n"
                "DCRï¼ˆå€Ÿå…¥å„Ÿé‚„ä½™è£•ç‡ï¼‰: NOI / ADSã€‚1.0ä»¥ä¸Šã§è¿”æ¸ˆä½™åŠ›ã‚ã‚Šã€‚1.3ä»¥ä¸ŠãŒå®‰å…¨æ°´æº–ã®ç›®å®‰ã€‚\n\n"
                "BERï¼ˆæç›Šåˆ†å²å…¥å±…ç‡ï¼‰: ï¼ˆé‹å–¶è²»ï¼‹å¹´é–“è¿”æ¸ˆé¡ï¼‰ / æº€å®¤æƒ³å®šå¹´é–“è³ƒæ–™ã€‚ã“ã®å…¥å±…ç‡ã‚’ä¸‹å›ã‚‹ã¨èµ¤å­—ã€‚70%ä»¥ä¸‹ãŒå®‰å…¨åœã®ç›®å®‰ã€‚\n\n"
                "ãƒ¬ãƒãƒ¬ãƒƒã‚¸åˆ¤å®š: FCR > K% ãªã‚‰ Positiveï¼ˆå€Ÿå…¥ã«ã‚ˆã‚Šåç›ŠãŒå¢—å¹…ï¼‰ã€‚Negative ã®å ´åˆã€å€Ÿå…¥ãŒåç›Šã‚’åœ§è¿«ã—ã¦ã„ã‚‹ã€‚\n\n"
                "IRRï¼ˆå†…éƒ¨åç›Šç‡ï¼‰: æŠ•è³‡æœŸé–“å…¨ä½“ï¼ˆä¿æœ‰ï¼‹å£²å´ï¼‰ã®å¹´é–“å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€‚æœŸå¾…åç›Šç‡ï¼ˆ5%ï¼‰ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒåˆ¤æ–­åŸºæº–ã€‚\n\n"
                "NPVï¼ˆæ­£å‘³ç¾åœ¨ä¾¡å€¤ï¼‰: å°†æ¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã®ç¾åœ¨ä¾¡å€¤åˆè¨ˆ âˆ’ åˆæœŸæŠ•è³‡é¡ã€‚0ä»¥ä¸Šã§ã‚ã‚Œã°æŠ•è³‡ä¾¡å€¤ã‚ã‚Šã€‚"
            )
            sections.append((legend_text, 'NORMAL_TEXT'))
        else:
            sections.append(("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸å¯ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰", 'NORMAL_TEXT'))

        # A4. æŠ•è³‡åˆ¤æ–­ã‚³ãƒ¡ãƒ³ãƒˆ
        sections.append(("A4. æŠ•è³‡åˆ¤æ–­ã‚³ãƒ¡ãƒ³ãƒˆ", 'HEADING_1'))
        if sim_result:
            d = sim_result['decision']
            m = sim_result['metrics']
            judgment_lines = []
            judgment_lines.append(f"ç·åˆåˆ¤å®š: {d['recommendation']}ï¼ˆ{d['pass_count']}/{d['total_count']}é …ç›®ã‚¯ãƒªã‚¢ï¼‰")
            judgment_lines.append("")
            for key, item in d['decisions'].items():
                mark = "â—‹" if item['pass'] else "Ã—"
                judgment_lines.append(f"  {mark} {item['label']}: {item['detail']}")
            if sim_result.get('warnings'):
                judgment_lines.append("")
                judgment_lines.append("â€» æ³¨æ„äº‹é …:")
                for w in sim_result['warnings']:
                    judgment_lines.append(f"  - {w}")
            sections.append(("\n".join(judgment_lines), 'NORMAL_TEXT'))

            # Geminiã«ã‚ˆã‚‹æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ
            try:
                p = sim_result['params']
                advice_prompt = f"""ã‚ãªãŸã¯ä¸å‹•ç”£æŠ•è³‡ã®å°‚é–€ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã«åŸºã¥ãã€æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

ç‰©ä»¶æƒ…å ±:
- ç‰©ä»¶ä¾¡æ ¼: {p['purchase_price']:,.0f}å††
- æº€å®¤æƒ³å®šè³ƒæ–™: æœˆé¡{p['full_occupancy_rent_monthly']:,.0f}å††ï¼ˆå¹´é¡{p['full_occupancy_rent_annual']:,.0f}å††ï¼‰
- æ§‹é€ : {detailed.get('structure', 'ä¸æ˜')}
- ç¯‰å¹´æœˆ: {detailed.get('year_built', 'ä¸æ˜')}
- æœ€å¯„é§…: {report_data['station']}

ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:
- è¡¨é¢åˆ©å›ã‚Š: {m['gross_yield']:.2%}
- FCRï¼ˆç·åç›Šç‡ï¼‰: {m['fcr']:.2%}
- K%ï¼ˆãƒ­ãƒ¼ãƒ³å®šæ•°ï¼‰: {m['k_percent']:.2%}
- CCRï¼ˆè‡ªå·±è³‡æœ¬é…å½“ç‡ï¼‰: {m['ccr']:.2%}
- DCRï¼ˆå€Ÿå…¥å„Ÿé‚„ä½™è£•ç‡ï¼‰: {m['dcr']:.2f}
- BERï¼ˆæç›Šåˆ†å²å…¥å±…ç‡ï¼‰: {m['ber']:.2%}
- ãƒ¬ãƒãƒ¬ãƒƒã‚¸: {m['leverage']}
- IRR: {m['irr']:.2%}
- NPV: {m['npv']:,.0f}å††
- ç·åˆåˆ¤å®š: {d['recommendation']}ï¼ˆ{d['pass_count']}/{d['total_count']}é …ç›®ã‚¯ãƒªã‚¢ï¼‰

ä»¥ä¸‹ã®å†…å®¹ã‚’å«ã‚ã¦ãã ã•ã„:
1. ã“ã®ç‰©ä»¶ã®æŠ•è³‡ã¨ã—ã¦ã®ç·åˆè©•ä¾¡ï¼ˆå¼·ã¿ãƒ»å¼±ã¿ï¼‰
2. ç‰¹ã«æ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯è¦å› 
{"3. æŠ•è³‡æ¨å¥¨ã«è»¢æ›ã™ã‚‹ãŸã‚ã®æ¡ä»¶ï¼ˆä¾‹: ç‰©ä»¶ä¾¡æ ¼ãŒâ—‹â—‹ä¸‡å††ä»¥ä¸‹ã«ãªã‚Œã°å…¨æŒ‡æ¨™ã‚¯ãƒªã‚¢ã¨ãªã‚‹ã€è³ƒæ–™ãŒæœˆé¡â—‹â—‹ä¸‡å††ä»¥ä¸Šãªã‚‰åç›Šæ€§æ”¹å–„ãªã©ã€å…·ä½“çš„ãªæ•°å€¤ã‚’æç¤ºï¼‰" if not d['all_pass'] else "3. æŠ•è³‡å®Ÿè¡Œæ™‚ã®ç•™æ„ç‚¹"}
4. äº¤æ¸‰æ™‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆæŒ‡å€¤ã®ç›®å®‰ãªã©ï¼‰

ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
è¦‹å‡ºã—ã«ã¯ç•ªå·ã‚’ä»˜ã‘ã¦åŒºåˆ¥ã—ã¦ãã ã•ã„ã€‚
"""
                advice_response = gemini_client.generate_content(advice_prompt)
                sections.append(("", 'NORMAL_TEXT'))
                sections.append(("æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹", 'HEADING_2'))
                sections.append((_strip_markdown(advice_response.text), 'NORMAL_TEXT'))
            except Exception as ae:
                print(f"æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {ae}")
        else:
            sections.append(("ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚æŠ•è³‡åˆ¤æ–­ä¸å¯", 'NORMAL_TEXT'))

        # å…è²¬äº‹é …
        sections.append(("", 'NORMAL_TEXT'))
        sections.append(("â€» æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯æŠ•è³‡åˆ¤æ–­ã®å‚è€ƒæƒ…å ±ã§ã‚ã‚Šã€æœ€çµ‚çš„ãªæŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã«ãŠã„ã¦è¡Œã£ã¦ãã ã•ã„ã€‚", 'NORMAL_TEXT'))
        sections.append((f"ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", 'NORMAL_TEXT'))

        # === Step 2: ãƒ†ã‚­ã‚¹ãƒˆä¸€æ‹¬æŒ¿å…¥ + ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ ===
        full_text = "\n".join(s[0] for s in sections)
        requests = [{'insertText': {'location': {'index': 1}, 'text': full_text}}]
        docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()

        # ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ï¼ˆæ®µè½ã‚¹ã‚¿ã‚¤ãƒ« + ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
        style_requests = []
        text_style_requests = []
        idx = 1
        for text, style in sections:
            end_idx = idx + len(text)
            if style != 'NORMAL_TEXT':
                style_requests.append({
                    'updateParagraphStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'paragraphStyle': {'namedStyleType': style},
                        'fields': 'namedStyleType'
                    }
                })
            idx = end_idx + 1

        if style_requests:
            docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': style_requests}).execute()

        # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒ»ãƒ•ã‚©ãƒ³ãƒˆé©ç”¨
        idx = 1
        for text, style in sections:
            end_idx = idx + len(text)
            if style == 'SUBTITLE':
                text_style_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'textStyle': {
                            'foregroundColor': _rgb({'red': 0.45, 'green': 0.45, 'blue': 0.45}),
                            'fontSize': {'magnitude': 11, 'unit': 'PT'},
                        },
                        'fields': 'foregroundColor,fontSize'
                    }
                })
                text_style_requests.append({
                    'updateParagraphStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'paragraphStyle': {
                            'spaceBelow': {'magnitude': 16, 'unit': 'PT'},
                            'borderBottom': {
                                'color': _rgb(_BORDER_COLOR),
                                'width': {'magnitude': 0.5, 'unit': 'PT'},
                                'padding': {'magnitude': 8, 'unit': 'PT'},
                                'dashStyle': 'SOLID',
                            },
                        },
                        'fields': 'spaceBelow,borderBottom'
                    }
                })
            elif style == 'TITLE':
                text_style_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'textStyle': {
                            'foregroundColor': _rgb(_NAVY),
                            'fontSize': {'magnitude': 22, 'unit': 'PT'},
                            'bold': True,
                        },
                        'fields': 'foregroundColor,fontSize,bold'
                    }
                })
            elif style == 'HEADING_1':
                text_style_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'textStyle': {
                            'foregroundColor': _rgb(_NAVY),
                            'fontSize': {'magnitude': 16, 'unit': 'PT'},
                            'bold': True,
                        },
                        'fields': 'foregroundColor,fontSize,bold'
                    }
                })
                # HEADING_1ã®ä¸‹ã«ç½«ç·šé¢¨ã®ã‚¹ãƒšãƒ¼ã‚·ãƒ³ã‚°
                text_style_requests.append({
                    'updateParagraphStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'paragraphStyle': {
                            'borderBottom': {
                                'color': _rgb(_NAVY),
                                'width': {'magnitude': 1.5, 'unit': 'PT'},
                                'padding': {'magnitude': 6, 'unit': 'PT'},
                                'dashStyle': 'SOLID',
                            },
                            'spaceBelow': {'magnitude': 10, 'unit': 'PT'},
                            'spaceAbove': {'magnitude': 18, 'unit': 'PT'},
                        },
                        'fields': 'borderBottom,spaceBelow,spaceAbove'
                    }
                })
            elif style == 'HEADING_2':
                text_style_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'textStyle': {
                            'foregroundColor': _rgb(_LIGHT_NAVY),
                            'fontSize': {'magnitude': 12, 'unit': 'PT'},
                            'bold': True,
                        },
                        'fields': 'foregroundColor,fontSize,bold'
                    }
                })
                text_style_requests.append({
                    'updateParagraphStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'paragraphStyle': {
                            'spaceBelow': {'magnitude': 6, 'unit': 'PT'},
                            'spaceAbove': {'magnitude': 12, 'unit': 'PT'},
                        },
                        'fields': 'spaceBelow,spaceAbove'
                    }
                })
            elif style == 'NORMAL_TEXT' and text and not text.startswith('{{'):
                text_style_requests.append({
                    'updateTextStyle': {
                        'range': {'startIndex': idx, 'endIndex': end_idx},
                        'textStyle': {
                            'fontSize': {'magnitude': 10, 'unit': 'PT'},
                        },
                        'fields': 'fontSize'
                    }
                })
            idx = end_idx + 1

        if text_style_requests:
            try:
                docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': text_style_requests}).execute()
            except Exception as e:
                print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")

        # === Step 3: ãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥ï¼ˆæœ«å°¾ã‹ã‚‰é€†é †ï¼‰ ===

        # æŠ•è³‡åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«
        if sim_result:
            p = sim_result['params']
            m = sim_result['metrics']
            d = sim_result['decision']

            def mark(passed):
                return "â—‹" if passed else "Ã—"

            sim_results_data = [
                ["æŒ‡æ¨™", "ç®—å‡ºå€¤", "åˆ¤æ–­åŸºæº–"],
                ["è¡¨é¢åˆ©å›ã‚Š", f"{m['gross_yield']:.2%}", "å‚è€ƒå€¤"],
                ["FCRï¼ˆç·åç›Šç‡ï¼‰", f"{m['fcr']:.2%}", f"FCR > K% â†’ {mark(d['decisions']['fcr_vs_k']['pass'])}"],
                ["K%ï¼ˆãƒ­ãƒ¼ãƒ³å®šæ•°ï¼‰", f"{m['k_percent']:.2%}", "å‚è€ƒå€¤"],
                ["CCRï¼ˆè‡ªå·±è³‡æœ¬é…å½“ç‡ï¼‰", f"{m['ccr']:.2%}", f"CCR > FCR â†’ {mark(d['decisions']['ccr_vs_fcr']['pass'])}"],
                ["ãƒ¬ãƒãƒ¬ãƒƒã‚¸åˆ†æ", m['leverage'], f"{mark(d['decisions']['ccr_vs_fcr']['pass'])}"],
                ["DCRï¼ˆå€Ÿå…¥å„Ÿé‚„ä½™è£•ç‡ï¼‰", f"{m['dcr']:.2f}", f"DCR â‰¥ 1.2 â†’ {mark(d['decisions']['dcr']['pass'])}"],
                ["BERï¼ˆæç›Šåˆ†å²å…¥å±…ç‡ï¼‰", f"{m['ber']:.2%}", f"BER â‰¤ 80% â†’ {mark(d['decisions']['ber']['pass'])}"],
            ]
            if m.get('irr') is not None:
                sim_results_data.append(["IRRï¼ˆå†…éƒ¨åç›Šç‡ï¼‰", f"{m['irr']:.2%}", f"IRR > æœŸå¾…åç›Šç‡ â†’ {mark(d['decisions']['irr']['pass'])}"])
            else:
                sim_results_data.append(["IRRï¼ˆå†…éƒ¨åç›Šç‡ï¼‰", "è¨ˆç®—ä¸å¯", "Ã—"])
            if m.get('npv') is not None:
                sim_results_data.append(["NPVï¼ˆæ­£å‘³ç¾åœ¨ä¾¡å€¤ï¼‰", f"Â¥{m['npv']:,.0f}", f"NPV > 0 â†’ {mark(d['decisions']['npv']['pass'])}"])
            else:
                sim_results_data.append(["NPVï¼ˆæ­£å‘³ç¾åœ¨ä¾¡å€¤ï¼‰", "è¨ˆç®—ä¸å¯", "Ã—"])

            _insert_table_at_placeholder(docs_service, doc_id, '{{TABLE_SIM_RESULTS}}', sim_results_data, 3)

            # è¨­å®šæ¡ä»¶ãƒ†ãƒ¼ãƒ–ãƒ«
            sim_cond_data = [
                ["æ¡ä»¶", "å€¤"],
                ["ç‰©ä»¶è³¼å…¥ä¾¡æ ¼", f"Â¥{p['purchase_price']:,.0f}"],
                ["è³¼å…¥è«¸è²»ç”¨ï¼ˆç´„8%ï¼‰", f"Â¥{p['purchase_expenses']:,.0f}"],
                ["è³¼å…¥ç·è²»ç”¨", f"Â¥{p['total_purchase_cost']:,.0f}"],
                ["LTVï¼ˆå€Ÿå…¥å‰²åˆï¼‰", f"{p['ltv']:.0%}"],
                ["ãƒ­ãƒ¼ãƒ³ç·é¡", f"Â¥{p['loan_amount']:,.0f}"],
                ["è‡ªå·±è³‡é‡‘", f"Â¥{p['equity']:,.0f}"],
                ["ãƒ­ãƒ¼ãƒ³é‡‘åˆ©", f"{p['interest_rate']:.3%}"],
                ["è¿”æ¸ˆæœŸé–“", f"{p['loan_term']}å¹´ï¼ˆå…ƒåˆ©å‡ç­‰ï¼‰"],
                ["ç©ºå®¤ç‡", f"{p.get('vacancy_rate', 0.05):.0%}"],
                ["ä¿æœ‰æœŸé–“", f"{p.get('holding_period', 10)}å¹´"],
            ]
            _insert_table_at_placeholder(docs_service, doc_id, '{{TABLE_SIM_CONDITIONS}}', sim_cond_data, 2)

        # ãƒ¬ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
        if detailed.get('rent_roll') and len(detailed['rent_roll']) > 0:
            rent_data = [["éƒ¨å±‹ç•ªå·", "é–“å–ã‚Šãƒ»åºƒã•", "æƒ³å®šè³ƒæ–™ï¼ˆæœˆé¡ï¼‰"]]
            for unit in detailed['rent_roll']:
                room = unit.get('room', unit.get('room_number', 'ä¸æ˜'))
                plan = unit.get('plan', unit.get('floor_plan', ''))
                area = unit.get('area', '')
                plan_area = f"{plan}" + (f"ï¼ˆ{area}ç•³ï¼‰" if area else "")
                rent = unit.get('rent') or 0
                try:
                    rent_val = float(rent) if rent else 0
                    rent_data.append([str(room), plan_area, f"Â¥{rent_val:,.0f}"])
                except (ValueError, TypeError):
                    rent_data.append([str(room), plan_area, str(rent)])
            _insert_table_at_placeholder(docs_service, doc_id, '{{TABLE_RENT_ROLL}}', rent_data, 3)

        # åŸºæœ¬æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
        basic_rows = [["é …ç›®", "å†…å®¹"]]
        # ä½æ‰€: detailed_dataï¼ˆGeminiæŠ½å‡ºï¼‰ã‚’å„ªå…ˆã€fallbackã§geocodeçµæœ
        address_display = detailed.get('address') or report_data.get('address', 'ä¸æ˜')
        basic_rows.append(["æ‰€åœ¨åœ°", address_display])
        # æœ€å¯„é§…: è·¯ç·šå + é§…å + å¾’æ­©è·é›¢ã®å½¢å¼ï¼ˆä¾‹: å°ç”°æ€¥æ±Ÿãƒå³¶ç·š å–„è¡Œé§… å¾’æ­©6åˆ†ï¼‰
        station_display = report_data['station']
        if detailed.get('railway_line'):
            station_display = f"{detailed['railway_line']} {station_display}"
        walking = report_data.get('walking_distance')
        if walking:
            station_display += f" å¾’æ­©{walking['duration_minutes']}åˆ†ï¼ˆ{walking['distance_text']}ï¼‰"
        basic_rows.append(["æœ€å¯„é§…", station_display])
        if detailed.get('price'):
            basic_rows.append(["ç‰©ä»¶ä¾¡æ ¼", f"Â¥{detailed['price']:,.0f}"])
        if detailed.get('structure'):
            basic_rows.append(["æ§‹é€ ", detailed['structure']])
        if detailed.get('year_built'):
            basic_rows.append(["ç¯‰å¹´æœˆ", str(detailed['year_built'])])
        if detailed.get('land_area'):
            basic_rows.append(["åœŸåœ°é¢ç©", f"{detailed['land_area']}ã¡"])
        if detailed.get('building_area'):
            basic_rows.append(["å»ºç‰©é¢ç©", f"{detailed['building_area']}ã¡"])
        if detailed.get('total_units'):
            basic_rows.append(["ç·æˆ¸æ•°", f"{int(detailed['total_units'])}æˆ¸"])
        if detailed.get('full_occupancy_rent'):
            basic_rows.append(["æº€å®¤æ™‚è³ƒæ–™", f"æœˆé¡Â¥{detailed['full_occupancy_rent']:,.0f}ï¼ˆå¹´é¡Â¥{detailed['full_occupancy_rent'] * 12:,.0f}ï¼‰"])
        if detailed.get('floor_plan'):
            basic_rows.append(["é–“å–ã‚Š", detailed['floor_plan']])
        # æ–°è¦è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        if detailed.get('rights_type'):
            basic_rows.append(["æ¨©åˆ©å½¢æ…‹", detailed['rights_type']])
        if detailed.get('city_planning'):
            basic_rows.append(["éƒ½å¸‚è¨ˆç”»", detailed['city_planning']])
        if detailed.get('zoning'):
            basic_rows.append(["ç”¨é€”åœ°åŸŸ", detailed['zoning']])
        if detailed.get('building_coverage_ratio'):
            basic_rows.append(["å»ºè”½ç‡", str(detailed['building_coverage_ratio'])])
        if detailed.get('floor_area_ratio'):
            basic_rows.append(["å®¹ç©ç‡", str(detailed['floor_area_ratio'])])
        if detailed.get('road_access'):
            basic_rows.append(["æ¥é“çŠ¶æ³", detailed['road_access']])
        if detailed.get('transaction_type'):
            basic_rows.append(["å–å¼•æ…‹æ§˜", detailed['transaction_type']])
        if sim_result:
            basic_rows.append(["è¡¨é¢åˆ©å›ã‚Š", f"{sim_result['metrics']['gross_yield']:.2%}"])
        if location and location.get('lat'):
            addr_for_maps = location.get('original_address') or address_display
            maps_url = f"https://www.google.com/maps/search/?api=1&query={urllib.parse.quote(addr_for_maps)}"
            basic_rows.append(["Google Maps", maps_url])

        _insert_table_at_placeholder(docs_service, doc_id, '{{TABLE_BASIC_INFO}}', basic_rows, 2)

        # åœ°å›³ç”»åƒæŒ¿å…¥
        if location and location.get('lat') and location.get('lng'):
            _insert_map_image(docs_service, drive_service, doc_id, location)

        # å‘¨è¾ºèª¿æŸ»ãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥ï¼ˆ_parse_structured_research_textã§ç”Ÿæˆã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
        if hasattr(create_evaluation_report, '_research_tables'):
            for table_id, table_content in create_evaluation_report._research_tables.items():
                try:
                    # ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è§£æ
                    lines = [l.strip() for l in table_content.strip().split('\n') if l.strip()]
                    if lines:
                        table_rows = []
                        for line in lines:
                            cols = [c.strip() for c in line.split('|') if c.strip()]
                            if cols:
                                table_rows.append(cols)
                        if table_rows:
                            col_count = max(len(r) for r in table_rows)
                            # åˆ—æ•°ã‚’çµ±ä¸€ï¼ˆè¶³ã‚Šãªã„å ´åˆã¯ç©ºæ–‡å­—ã§åŸ‹ã‚ã‚‹ï¼‰
                            for row in table_rows:
                                while len(row) < col_count:
                                    row.append('')
                            _insert_table_at_placeholder(
                                docs_service, doc_id,
                                f'{{{{{table_id}}}}}',
                                table_rows, col_count
                            )
                except Exception as te:
                    print(f"å‘¨è¾ºèª¿æŸ»ãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥ã‚¨ãƒ©ãƒ¼ ({table_id}): {te}")
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            create_evaluation_report._research_tables = {}

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç‰©ä»¶ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
        file = drive_service.files().get(fileId=doc_id, fields='parents').execute()
        previous_parents = ",".join(file.get('parents'))
        drive_service.files().update(
            fileId=doc_id,
            addParents=folder_id,
            removeParents=previous_parents,
            fields='id, parents'
        ).execute()

        print(f"ãƒ¬ãƒãƒ¼ãƒˆä½œæˆå®Œäº†: {title}")
        return doc_id

    except Exception as e:
        print(f"ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_property_evaluation_report(
    drive_service,
    docs_service,
    gmaps_client,
    gemini_client,
    folder_id: str,
    pdf_file_id: str,
    property_number: str,
    station: str,
    extracted_text: Optional[str] = None,
    detailed_data: Optional[dict] = None
) -> Optional[str]:
    """ç‰©ä»¶è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼"""

    print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹: ç‰©ä»¶ç•ªå·={property_number}")

    try:
        # 1. ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆæ—¢ã«æŠ½å‡ºæ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
        if extracted_text:
            text = extracted_text
            print(f"æŠ½å‡ºæ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨: {len(text)} æ–‡å­—")
        else:
            # PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            request = drive_service.files().get_media(fileId=pdf_file_id)
            fh = io.BytesIO()
            from googleapiclient.http import MediaIoBaseDownload
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

            pdf_data = fh.getvalue()
            print(f"PDFå–å¾—å®Œäº†: {len(pdf_data)} bytes")

            text = extract_text_from_pdf(pdf_data)
            if not text:
                print("ã‚¨ãƒ©ãƒ¼: PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—")
                return None
            print(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†: {len(text)} æ–‡å­—")

        # 3. ä½æ‰€æŠ½å‡ºï¼ˆdetailed_dataå„ªå…ˆ â†’ æ­£è¦è¡¨ç¾ â†’ Geminiãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        address = None
        if detailed_data and detailed_data.get('address'):
            address = detailed_data['address']
            print(f"GeminiæŠ½å‡ºä½æ‰€ã‚’ä½¿ç”¨: {address}")
        if not address:
            address = extract_address_with_regex(text)
        if not address:
            print("æ­£è¦è¡¨ç¾ã§ä½æ‰€æŠ½å‡ºå¤±æ•—ã€Geminiã‚’ä½¿ç”¨")
            address = extract_address_with_gemini(text, gemini_client)

        if not address:
            print("ã‚¨ãƒ©ãƒ¼: ä½æ‰€æŠ½å‡ºå¤±æ•—")
            return None
        print(f"ä½æ‰€æŠ½å‡ºå®Œäº†: {address}")

        # 4. ä½ç½®æƒ…å ±å–å¾—
        location = geocode_address(address, gmaps_client)
        if not location:
            print("ã‚¨ãƒ©ãƒ¼: Geocodingå¤±æ•—")
            return None
        print(f"ä½ç½®æƒ…å ±å–å¾—å®Œäº†: {location}")

        # 4.5. å¾’æ­©è·é›¢è¨ˆç®—ï¼ˆGoogle Maps Distance Matrix APIï¼‰
        walking_distance = calculate_walking_distance(location, station, gmaps_client)

        # 5. ç›¸å ´èª¿æŸ»ï¼ˆGeminiï¼‰
        dd = detailed_data or {}
        property_info = {
            'property_number': property_number,
            'station': station,
            'walking_distance': walking_distance,
            'structure': dd.get('structure'),
            'year_built': dd.get('year_built'),
            'floor_plan': dd.get('floor_plan'),
            'building_area': dd.get('building_area'),
            'total_units': dd.get('total_units'),
        }
        market_data = research_market_price(location, property_info, gemini_client)
        print(f"ç›¸å ´èª¿æŸ»å®Œäº†: {market_data['status']}")

        # 5.5. ã‚¨ãƒªã‚¢èª¿æŸ»ï¼ˆGemini Web Searchï¼‰
        area_data = research_area_with_gemini_search(location, property_info, gemini_client)
        print(f"ã‚¨ãƒªã‚¢èª¿æŸ»å®Œäº†: {area_data['status']}")

        # ä¸¡æ–¹ã®èª¿æŸ»çµæœã‚’çµ±åˆ
        combined_report = combine_research_reports(market_data, area_data)

        # 6. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report_data = {
            'property_number': property_number,
            'station': station,
            'address': location['formatted_address'],
            'location': location,
            'walking_distance': walking_distance,
            'market_report': combined_report,
            'detailed_data': detailed_data or {}
        }

        doc_id = create_evaluation_report(docs_service, drive_service, folder_id, report_data, gemini_client=gemini_client)

        if doc_id:
            print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: Doc ID={doc_id}")
            return doc_id
        else:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¬ãƒãƒ¼ãƒˆä½œæˆå¤±æ•—")
            return None

    except Exception as e:
        print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

def get_or_create_label(gmail_service, label_name):
    """Gmailãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    labels = gmail_service.users().labels().list(userId='me').execute()
    for label in labels.get('labels', []):
        if label['name'] == label_name:
            return label['id']

    # ãƒ©ãƒ™ãƒ«ä½œæˆ
    label = gmail_service.users().labels().create(
        userId='me',
        body={'name': label_name}
    ).execute()
    return label['id']

def extract_property_info_from_hanbaizumen(message_body, attachments):
    """è²©å£²å›³é¢ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºï¼ˆGeminiä½¿ç”¨ï¼‰"""
    property_number = None
    station = None
    detailed_data = {}

    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç‰©ä»¶ç•ªå·ã‚’æŠ½å‡ºï¼ˆå„ªå…ˆï¼‰
    for att in attachments:
        match = re.search(r'Hanbaizumen_(\d+)', att.get('filename', ''))
        if match:
            property_number = match.group(1)
            break

    # Gemini APIã§æœ¬æ–‡ã‹ã‚‰ç‰©ä»¶ç•ªå·ã¨é§…åã‚’æŠ½å‡º
    try:
        gemini_client = get_gemini_client()

        prompt = f"""ã‚ãªãŸã¯ä¸å‹•ç”£ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ã‚¿ã‚¹ã‚¯: ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‹ã‚‰ç‰©ä»¶ç•ªå·ã¨æœ€å¯„é§…ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

æŠ½å‡ºæ¡ä»¶:
- ç‰©ä»¶ç•ªå·: "ç‰©ä»¶ç•ªå·:æ•°å­—" "ç‰©ä»¶ç•ªå·ï¼šæ•°å­—" "hid=æ•°å­—" ã¨ã„ã†è¨˜è¼‰ã‹ã‚‰æ•°å­—éƒ¨åˆ†ã®ã¿
- é§…å: "é§…å+é§…" "é§…:é§…å" "é§…ï¼šé§…å" ã¨ã„ã†è¨˜è¼‰ã‹ã‚‰é§…åéƒ¨åˆ†ã®ã¿ï¼ˆã€Œé§…ã€ã¨ã„ã†æ–‡å­—ã¯é™¤ãï¼‰
- è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯null

é‡è¦: ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã«å®Ÿéš›ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹æƒ…å ±ã®ã¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚æ¨æ¸¬ãƒ»è£œå®Œã¯ç¦æ­¢ã§ã™ã€‚

=== ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã“ã“ã‹ã‚‰ ===
{message_body}
=== ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã“ã“ã¾ã§ ===

JSONå½¢å¼ã§å›ç­”:
{{"property_number": "æ•°å­—ã®ã¿", "station": "é§…åã®ã¿"}}"""

        response = gemini_client.generate_content(prompt)
        result_text = response.text.strip()

        # JSONã¨ã—ã¦è§£æ
        import json
        # ```json ``` ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é™¤å»
        if result_text.startswith('```'):
            result_text = result_text.split('```')[1]
            if result_text.startswith('json'):
                result_text = result_text[4:]
            result_text = result_text.strip()

        result = json.loads(result_text)

        # ç‰©ä»¶ç•ªå·ï¼ˆæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å–å¾—ã§ãã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
        if not property_number and result.get('property_number'):
            property_number = str(result['property_number'])

        # é§…å
        if result.get('station'):
            station = result['station']

        print(f"âœ… GeminiæŠ½å‡ºæˆåŠŸ - ç‰©ä»¶ç•ªå·: {property_number}, é§…: {station}")

        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åŒ…æ‹¬çš„ãªç‰©ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        for att in attachments:
            filename = att.get('filename', '')
            attachment_id = att['body'].get('attachmentId')

            if attachment_id and (filename.lower().endswith('.pdf') or
                                filename.lower().endswith(('.jpg', '.jpeg', '.png'))):
                try:
                    import base64
                    # attachmentã¯æ—¢ã«process_email_typeã§å–å¾—ã•ã‚Œã‚‹å‰æã ãŒã€
                    # ã“ã“ã§ã¯æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿å‚ç…§
                    # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯å¾Œã§process_email_typeã§å–å¾—ã•ã‚Œã‚‹
                    print(f"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºï¼ˆè©³ç´°æŠ½å‡ºã¯å¾Œã§å®Ÿè¡Œï¼‰: {filename}")
                except Exception as att_e:
                    print(f"âš ï¸  æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {att_e}")

    except Exception as e:
        print(f"âš ï¸  GeminiæŠ½å‡ºã‚¨ãƒ©ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œï¼‰: {e}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLã‹ã‚‰ç‰©ä»¶ç•ªå·ã‚’å–å¾—
        if not property_number:
            url_match = re.search(r'hid=(\d+)', message_body)
            if url_match:
                property_number = url_match.group(1)
                print(f"ğŸ“ URLã‹ã‚‰ç‰©ä»¶ç•ªå·æŠ½å‡º: {property_number}")

    if not station:
        station = 'ä¸æ˜'

    return {
        'property_number': property_number,
        'station': station,
        'detailed_data': detailed_data
    }

def extract_property_info_from_chizu(message_body):
    """ä½å®…åœ°å›³ãƒ»è·¯ç·šä¾¡å›³ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ç‰©ä»¶æƒ…å ±ã‚’æŠ½å‡º"""
    property_number = None
    station = None

    # æœ¬æ–‡ã‹ã‚‰ç‰©ä»¶ç•ªå·ã¨é§…åã‚’æŠ½å‡º
    match = re.search(r'ç‰©ä»¶ç•ªå·[:ï¼š]\s*(\d+)\s*é§…[:ï¼š]\s*([^\s\r\n]+)', message_body)
    if match:
        property_number = match.group(1)
        station = match.group(2)

    # URLã‹ã‚‰ç‰©ä»¶ç•ªå·ã‚’å–å¾—ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
    if not property_number:
        url_match = re.search(r'hid=(\d+)', message_body)
        if url_match:
            property_number = url_match.group(1)

    # é§…åãŒå–ã‚Œãªã‹ã£ãŸå ´åˆ
    if not station:
        station_match = re.search(r'é§…[:ï¼š]\s*([^\s\r\n,ã€]+)', message_body)
        if station_match:
            station = station_match.group(1)

    if not station:
        station = 'ä¸æ˜'

    # æ–°å½¢å¼ï¼ˆdictï¼‰ã§è¿”ã™
    return {
        'property_number': property_number,
        'station': station,
        'detailed_data': {}
    }

def get_or_create_folder(drive_service, parent_folder_id, folder_name, property_number):
    """Driveãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—ã¾ãŸã¯ä½œæˆï¼ˆç‰©ä»¶ç•ªå·ã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ï¼‰"""
    # ã¾ãšå®Œå…¨ä¸€è‡´ã§æ¤œç´¢
    query = f"name = '{folder_name}' and '{parent_folder_id}' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
    results = drive_service.files().list(q=query, fields='files(id, name)').execute()
    files = results.get('files', [])

    if files:
        return files[0]['id']

    # ç‰©ä»¶ç•ªå·ã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
    partial_query = f"name contains '_{property_number}' and '{parent_folder_id}' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
    partial_results = drive_service.files().list(q=partial_query, fields='files(id, name)', pageSize=10).execute()
    partial_files = partial_results.get('files', [])

    if partial_files:
        for folder in partial_files:
            if folder['name'].endswith(f'_{property_number}'):
                print(f"æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨: {folder['name']}")
                return folder['id']

    # æ–°è¦ä½œæˆ
    print(f"ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {folder_name}")
    folder_metadata = {
        'name': folder_name,
        'mimeType': 'application/vnd.google-apps.folder',
        'parents': [parent_folder_id]
    }
    folder = drive_service.files().create(body=folder_metadata, fields='id').execute()
    return folder['id']

def save_attachment(drive_service, folder_id, filename, content):
    """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Driveã«ä¿å­˜"""
    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
    query = f"name = '{filename}' and '{folder_id}' in parents and trashed = false"
    results = drive_service.files().list(q=query, fields='files(id)').execute()
    if results.get('files'):
        return  # æ—¢ã«å­˜åœ¨

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    file_metadata = {
        'name': filename,
        'parents': [folder_id]
    }
    drive_service.files().create(
        body=file_metadata,
        media_body=content,
        fields='id'
    ).execute()

def process_email_type(gmail, drive, query, label_name, processed_label_id, investment_folder_id, extract_info_fn):
    """ç‰¹å®šã‚¿ã‚¤ãƒ—ã®ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†"""
    results = []

    response = gmail.users().messages().list(userId='me', q=query).execute()
    messages = response.get('messages', [])

    print(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
    print(f"è©²å½“ãƒ¡ãƒ¼ãƒ«æ•°: {len(messages)}")

    for msg in messages:
        try:
            message = gmail.users().messages().get(userId='me', id=msg['id']).execute()

            # æœ¬æ–‡å–å¾—ï¼ˆå†å¸°çš„ã«partsã‚’æ¢ç´¢ï¼‰
            import base64
            body = ""
            attachments = []

            def extract_body_and_attachments(parts):
                nonlocal body, attachments
                for part in parts:
                    mime_type = part.get('mimeType', '')

                    # text/plain ã‚’è¦‹ã¤ã‘ãŸã‚‰æœ¬æ–‡ã¨ã—ã¦å–å¾—
                    if mime_type == 'text/plain' and 'data' in part.get('body', {}):
                        body = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8', errors='ignore')

                    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
                    if part.get('filename'):
                        attachments.append(part)

                    # multipart/* ã®å ´åˆã¯å†å¸°çš„ã«æ¢ç´¢
                    if mime_type.startswith('multipart/') and 'parts' in part:
                        extract_body_and_attachments(part['parts'])

            if 'parts' in message['payload']:
                extract_body_and_attachments(message['payload']['parts'])

            # parts ãŒãªã„ã€ã¾ãŸã¯bodyãŒç©ºã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not body and 'body' in message['payload'] and 'data' in message['payload']['body']:
                body = base64.urlsafe_b64decode(message['payload']['body']['data']).decode('utf-8', errors='ignore')

            # ç‰©ä»¶æƒ…å ±æŠ½å‡ºï¼ˆé–¢æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§å‘¼ã³åˆ†ã‘ï¼‰
            import inspect
            sig = inspect.signature(extract_info_fn)
            param_count = len(sig.parameters)
            info = extract_info_fn(body, attachments) if param_count > 1 else extract_info_fn(body)

            # æ–°å½¢å¼ï¼ˆdictï¼‰ã¨æ—§å½¢å¼ï¼ˆtupleï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œ
            if isinstance(info, dict):
                property_number = info.get('property_number')
                station = info.get('station')
                detailed_data = info.get('detailed_data', {})
            else:
                # æ—§å½¢å¼ï¼ˆtupleï¼‰
                property_number, station = info
                detailed_data = {}

            if not property_number:
                print(f"âš ï¸  ç‰©ä»¶ç•ªå·ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {message.get('snippet', '')[:50]}")
                # ç‰©ä»¶ç•ªå·ãŒãªã„å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã®ä¸€éƒ¨ã‚’ä½¿ç”¨
                property_number = msg['id'][:8]

            print(f"å‡¦ç†ä¸­: ç‰©ä»¶ç•ªå·={property_number} é§…={station}")

            # ãƒ¡ãƒ¼ãƒ«å—ä¿¡æ—¥ã‚’å–å¾—
            date_str = datetime.now().strftime('%Y%m%d')

            # ãƒ•ã‚©ãƒ«ãƒ€åã‚’ç”Ÿæˆ
            folder_name = f"{date_str}_{station}_{property_number}"

            # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
            folder_id = get_or_create_folder(drive, investment_folder_id, folder_name, property_number)

            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            for part in attachments:
                filename = part.get('filename')
                attachment_id = part['body'].get('attachmentId')

                if attachment_id:
                    attachment = gmail.users().messages().attachments().get(
                        userId='me', messageId=msg['id'], id=attachment_id
                    ).execute()

                    import base64
                    file_data = base64.urlsafe_b64decode(attachment['data'])

                    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
                    query_file = f"name = '{filename}' and '{folder_id}' in parents and trashed = false"
                    existing = drive.files().list(q=query_file, fields='files(id)').execute()

                    if existing.get('files'):
                        print(f"ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ï¼‰: {filename}")
                        continue

                    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                    from io import BytesIO
                    from googleapiclient.http import MediaIoBaseUpload

                    media = MediaIoBaseUpload(BytesIO(file_data), mimetype='application/octet-stream', resumable=True)
                    file_metadata = {
                        'name': filename,
                        'parents': [folder_id]
                    }
                    uploaded_file = drive.files().create(body=file_metadata, media_body=media, fields='id').execute()
                    print(f"ä¿å­˜å®Œäº†: {filename} â†’ {folder_name}")

                    # PDF/ç”»åƒã®å ´åˆã€ä¸­èº«ã‚’ç¢ºèªã—ã¦è²©å£²å›³é¢ã‹åˆ¤å®š
                    is_pdf = filename.lower().endswith('.pdf')
                    is_image = filename.lower().endswith(('.jpg', '.jpeg', '.png'))

                    if is_pdf or is_image:
                        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                        if is_pdf:
                            extracted_text = extract_text_from_pdf(file_data)
                        else:  # ç”»åƒ
                            gemini_client = get_gemini_client()
                            extracted_text = extract_text_from_image(file_data, gemini_client)

                        if is_hanbaizumen(extracted_text):
                            try:
                                print(f"è²©å£²å›³é¢æ¤œå‡ºã€è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’é–‹å§‹: {filename}")

                                # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
                                docs_service = get_docs_service()
                                gmaps_client = get_gmaps_client()
                                gemini_client = get_gemini_client()

                                # åŒ…æ‹¬çš„ãªç‰©ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                                comprehensive_data = extract_comprehensive_property_data(
                                    file_data, filename, gemini_client
                                )
                                print(f"è©³ç´°ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†: {len(comprehensive_data)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")

                                # æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                                simulation_result = None
                                try:
                                    simulation_result = run_simulation(comprehensive_data)
                                    if simulation_result:
                                        print(f"æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {simulation_result['decision']['recommendation']}")
                                        excel_file_id = create_simulation_excel(
                                            simulation_result,
                                            {"property_number": property_number, "station": station},
                                            drive, folder_id
                                        )
                                        if excel_file_id:
                                            print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³Excelä¿å­˜å®Œäº†: {excel_file_id}")
                                    else:
                                        print("æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰")
                                except Exception as sim_e:
                                    print(f"æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {sim_e}")
                                    import traceback
                                    traceback.print_exc()

                                if simulation_result:
                                    comprehensive_data['simulation_result'] = simulation_result

                                # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆextracted_textã¨è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ï¼‰
                                report_doc_id = generate_property_evaluation_report(
                                    drive_service=drive,
                                    docs_service=docs_service,
                                    gmaps_client=gmaps_client,
                                    gemini_client=gemini_client,
                                    folder_id=folder_id,
                                    pdf_file_id=uploaded_file['id'],
                                    property_number=property_number,
                                    station=station,
                                    extracted_text=extracted_text,
                                    detailed_data=comprehensive_data
                                )

                                if report_doc_id:
                                    print(f"è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸ: {report_doc_id}")
                                else:
                                    print(f"è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰")
                            except Exception as e:
                                print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                                import traceback
                                traceback.print_exc()

            # å‡¦ç†æ¸ˆã¿ãƒ©ãƒ™ãƒ«è¿½åŠ 
            gmail.users().messages().modify(
                userId='me',
                id=msg['id'],
                body={'addLabelIds': [processed_label_id]}
            ).execute()

            results.append(f"Processed: {folder_name}")

        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()

    return results

def process_emails():
    """ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†"""
    gmail = get_gmail_service()
    drive = get_drive_service()

    investment_folder_id = get_secret("INVESTMENT_FOLDER_ID")
    label_name = get_secret("PROCESSED_LABEL_NAME")
    processed_label_id = get_or_create_label(gmail, label_name)

    all_results = []

    # è²©å£²å›³é¢ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†
    query1 = f'subject:è²©å£²å›³é¢ newer_than:15m has:attachment -label:{label_name}'
    results1 = process_email_type(
        gmail, drive, query1, label_name, processed_label_id,
        investment_folder_id, extract_property_info_from_hanbaizumen
    )
    all_results.extend(results1)

    # ä½å®…åœ°å›³ãƒ»è·¯ç·šä¾¡å›³ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†
    query2 = f'subject:ä½å®…åœ°å›³ãƒ»è·¯ç·šä¾¡å›³ newer_than:15m has:attachment -label:{label_name}'
    results2 = process_email_type(
        gmail, drive, query2, label_name, processed_label_id,
        investment_folder_id, extract_property_info_from_chizu
    )
    all_results.extend(results2)

    return all_results

@app.route('/', methods=['GET'])
def index():
    """æ‰‹å‹•å®Ÿè¡Œç”¨WebUI"""
    html = """
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Email Organizer - æ‰‹å‹•å®Ÿè¡Œ</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
                max-width: 800px;
                margin: 50px auto;
                padding: 20px;
                background: #f5f5f5;
            }
            .container {
                background: white;
                padding: 30px;
                border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }
            h1 { color: #333; margin-top: 0; }
            button {
                background: #4285f4;
                color: white;
                border: none;
                padding: 12px 24px;
                font-size: 16px;
                border-radius: 4px;
                cursor: pointer;
                transition: background 0.3s;
            }
            button:hover { background: #357ae8; }
            button:disabled { background: #ccc; cursor: not-allowed; }
            #result {
                margin-top: 20px;
                padding: 15px;
                border-radius: 4px;
                display: none;
            }
            .success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
            .error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
            .loading { background: #fff3cd; color: #856404; border: 1px solid #ffeaa7; }
            pre { background: #f5f5f5; padding: 10px; border-radius: 4px; overflow-x: auto; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ“§ Email Organizer</h1>
            <p>è²©å£²å›³é¢ãƒ»ä½å®…åœ°å›³ãƒ¡ãƒ¼ãƒ«ã‚’æ‰‹å‹•ã§å‡¦ç†ã—ã¾ã™</p>
            <button onclick="runProcess()" id="runBtn">ğŸš€ ãƒ¡ãƒ¼ãƒ«æ•´ç†ã‚’å®Ÿè¡Œ</button>
            <div id="result"></div>
        </div>
        <script>
            async function runProcess() {
                const btn = document.getElementById('runBtn');
                const result = document.getElementById('result');

                btn.disabled = true;
                result.className = 'loading';
                result.style.display = 'block';
                result.innerHTML = 'â³ å‡¦ç†ä¸­...';

                try {
                    const response = await fetch('/process', { method: 'POST' });
                    const data = await response.json();

                    if (response.ok) {
                        result.className = 'success';
                        result.innerHTML = `
                            <strong>âœ… å‡¦ç†å®Œäº†</strong><br>
                            å‡¦ç†ä»¶æ•°: ${data.processed}ä»¶<br>
                            <pre>${JSON.stringify(data.details, null, 2)}</pre>
                        `;
                    } else {
                        throw new Error(data.message || 'å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ');
                    }
                } catch (error) {
                    result.className = 'error';
                    result.innerHTML = `<strong>âŒ ã‚¨ãƒ©ãƒ¼</strong><br>${error.message}`;
                } finally {
                    btn.disabled = false;
                }
            }
        </script>
    </body>
    </html>
    """
    return html

@app.route('/health', methods=['GET'])
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({"status": "ok"})

@app.route('/process', methods=['POST'])
def process():
    """ãƒ¡ãƒ¼ãƒ«å‡¦ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        results = process_emails()
        return jsonify({
            "status": "success",
            "processed": len(results),
            "details": results
        })
    except Exception as e:
        import traceback
        print(f"ERROR: {e}")
        print(traceback.format_exc())
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

@app.route('/test/<folder_id>', methods=['POST'])
def test_folder(folder_id):
    """æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã®PDFã‹ã‚‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³+ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’ãƒ†ã‚¹ãƒˆï¼ˆãƒ¡ãƒ¼ãƒ«å—ä¿¡ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
    try:
        drive = get_drive_service()

        # ãƒ•ã‚©ãƒ«ãƒ€æƒ…å ±å–å¾—
        folder_info = drive.files().get(fileId=folder_id, fields='name').execute()
        folder_name = folder_info['name']
        parts = folder_name.split('_')
        if len(parts) >= 3:
            property_number, station = parts[2], parts[1]
        elif len(parts) == 2:
            property_number, station = parts[1], parts[0]
        else:
            property_number, station = folder_name, 'ä¸æ˜'

        print(f"ãƒ†ã‚¹ãƒˆé–‹å§‹: {folder_name} (ç‰©ä»¶:{property_number}, é§…:{station})")

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDF/ç”»åƒã‚’æ¤œç´¢
        query = f"'{folder_id}' in parents and trashed=false and (mimeType='application/pdf' or mimeType contains 'image/')"
        files = drive.files().list(q=query, fields='files(id, name, mimeType)', pageSize=10).execute().get('files', [])

        if not files:
            return jsonify({"status": "error", "message": "PDF/ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}), 404

        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã—ã¦è²©å£²å›³é¢ã‚’æ¢ã™
        from googleapiclient.http import MediaIoBaseDownload
        gemini_client = get_gemini_client()
        target = None
        file_data = None
        extracted_text = ''
        is_sales = False

        # è²·ä»˜æ›¸ãƒ»åœ°å›³ã‚’å¾Œå›ã—ã«ã‚½ãƒ¼ãƒˆ
        def sort_key(f):
            name = f['name'].lower()
            if name.startswith('kaitsuke') or name.startswith('map'):
                return 1
            return 0
        sorted_files = sorted(files, key=sort_key)

        for candidate in sorted_files:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªä¸­: {candidate['name']}")
            req = drive.files().get_media(fileId=candidate['id'])
            fh = io.BytesIO()
            dl = MediaIoBaseDownload(fh, req)
            done = False
            while not done:
                _, done = dl.next_chunk()
            candidate_data = fh.getvalue()

            is_pdf = candidate['name'].lower().endswith('.pdf')
            if is_pdf:
                candidate_text = extract_text_from_pdf(candidate_data)
            else:
                candidate_text = extract_text_from_image(candidate_data, gemini_client)

            if is_hanbaizumen(candidate_text):
                target = candidate
                file_data = candidate_data
                extracted_text = candidate_text
                is_sales = True
                print(f"è²©å£²å›³é¢ç™ºè¦‹: {candidate['name']}")
                break
            print(f"  â†’ è²©å£²å›³é¢ã§ã¯ãªã„ ({len(candidate_text)}æ–‡å­—)")

        # è²©å£²å›³é¢ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        if target is None:
            target = sorted_files[0]
            req = drive.files().get_media(fileId=target['id'])
            fh = io.BytesIO()
            dl = MediaIoBaseDownload(fh, req)
            done = False
            while not done:
                _, done = dl.next_chunk()
            file_data = fh.getvalue()
            is_pdf_fallback = target['name'].lower().endswith('.pdf')
            if is_pdf_fallback:
                extracted_text = extract_text_from_pdf(file_data)
            else:
                extracted_text = extract_text_from_image(file_data, gemini_client)
            print(f"è²©å£²å›³é¢ãªã—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {target['name']}")

        print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {target['name']} (è²©å£²å›³é¢: {is_sales})")

        # åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        comprehensive_data = extract_comprehensive_property_data(file_data, target['name'], gemini_client)
        print(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†: {len(comprehensive_data)} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        simulation_result = None
        excel_file_id = None
        try:
            simulation_result = run_simulation(comprehensive_data)
            if simulation_result:
                print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {simulation_result['decision']['recommendation']}")
                excel_file_id = create_simulation_excel(
                    simulation_result,
                    {"property_number": property_number, "station": station},
                    drive, folder_id
                )
                if excel_file_id:
                    print(f"Excelä¿å­˜å®Œäº†: {excel_file_id}")
                comprehensive_data['simulation_result'] = simulation_result
            else:
                print("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰")
        except Exception as sim_e:
            print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {sim_e}")
            import traceback
            traceback.print_exc()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        docs_service = get_docs_service()
        gmaps_client = get_gmaps_client()
        report_doc_id = generate_property_evaluation_report(
            drive_service=drive,
            docs_service=docs_service,
            gmaps_client=gmaps_client,
            gemini_client=gemini_client,
            folder_id=folder_id,
            pdf_file_id=target['id'],
            property_number=property_number,
            station=station,
            extracted_text=extracted_text,
            detailed_data=comprehensive_data,
        )

        result = {
            "status": "success",
            "folder": folder_name,
            "property_number": property_number,
            "station": station,
            "target_file": target['name'],
            "is_hanbaizumen": is_sales,
            "data_fields": len(comprehensive_data),
            "simulation": simulation_result['decision']['recommendation'] if simulation_result else "ã‚¹ã‚­ãƒƒãƒ—",
            "excel_file_id": excel_file_id,
            "report_doc_id": report_doc_id,
        }
        print(f"ãƒ†ã‚¹ãƒˆå®Œäº†: {result}")
        return jsonify(result)

    except Exception as e:
        import traceback
        print(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route('/test/list', methods=['GET'])
def test_list_folders():
    """æŠ•è³‡ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç‰©ä»¶ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’å–å¾—"""
    try:
        drive = get_drive_service()
        investment_folder_id = get_secret("INVESTMENT_FOLDER_ID")

        query = f"'{investment_folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
        results = drive.files().list(
            q=query, fields='files(id, name)', orderBy='name desc', pageSize=20
        ).execute()
        folders = results.get('files', [])

        folder_list = []
        for folder in folders:
            fquery = f"'{folder['id']}' in parents and trashed=false"
            files = drive.files().list(q=fquery, fields='files(mimeType)', pageSize=50).execute().get('files', [])
            file_types = {}
            for f in files:
                mt = f['mimeType'].split('/')[-1]
                file_types[mt] = file_types.get(mt, 0) + 1
            folder_list.append({
                "id": folder['id'],
                "name": folder['name'],
                "files": file_types,
            })

        return jsonify({"status": "success", "folders": folder_list})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)
